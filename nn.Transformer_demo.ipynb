{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pytorch中 nn.Transformer的使用详解与Transformer的黑盒讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 本文内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Transformer是个相对复杂的模型，可能有些人和我一样，学了也不会用，或者感觉自己懂了，但又不懂。本文将Transformer看做一个黑盒，然后讲解Pytorch中nn.Transformer的使用。\n",
    "\n",
    "本文包含内容如下：\n",
    "\n",
    "1. Transformer的训练过程讲解\n",
    "2. Transformer的推理过程讲解\n",
    "3. Transformer的入参和出参讲解\n",
    "4. nn.Transformer的各个参数讲解\n",
    "5. nn.Transformer的mask机制详解\n",
    "6. 实战：使用nn.Transformer训练一个copy任务。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "开始之前，我们先导入要用到的包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 将Transformer看成黑盒\n",
    "\n",
    "这是一张经典的Transformer模型图：\n",
    "\n",
    "<img src=\"./images/transformer.png\" width=\"300\">\n",
    "\n",
    "\n",
    "我们现在将其变成黑盒，将其盖住：\n",
    "\n",
    "<img src=\"./images/transformer_1.png\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "我们现在再来看下Transformer的输入和输出：\n",
    "\n",
    "<img src=\"./images/transformer_2.jpg\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里是一个翻译任务中transformer的输入和输出。transformer的输入包含两部分：\n",
    "\n",
    "- inputs: 原句子对应的tokens，且是完整句子。一般0表示句子开始(`<bos>`)，1表示句子结束(`<eos>`)，2为填充(`<pad>`)。填充的目的是为了让不同长度的句子变为同一个长度，这样才可以组成一个batch。在代码中，该变量一般取名**src**。\n",
    "- outputs(shifted right)：上一个阶段的输出。虽然名字叫outputs，但是它是输入。最开始为0（`<bos>`），然后本次预测出“我”后，下次调用Transformer的该输入就变成`<bos> 我`。在代码中，该变量一般取名**tgt**。\n",
    "\n",
    "Transformer的输出是一个概率分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transformer的推理过程\n",
    "\n",
    "这里先讲Transformer的推理过程，因为这个简单。其实通过上面的讲解，你可能已经清楚了。上面是Transformer推理的第一步，紧接着第二步如图：\n",
    "\n",
    "<img src=\"./images/transformer_3.jpg\" width=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "Transformer的推理过程就是这样一遍一遍调用Transformer，直到输出`<eos>`或达到句子最大长度为止。\n",
    "\n",
    "\n",
    "> 通常真正在实战时，Transformer的Encoder部分只需要执行一遍就行了，这里为了简单起见，就整体重新执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transformer的训练过程\n",
    "\n",
    "在Transformer推理时，我们是一个词一个词的输出，但在训练时这样做效率太低了，所以我们会将target一次性给到Transformer（当然，你也可以按照推理过程做），如图所示：\n",
    "\n",
    "<img src=\"./images/transformer_4.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "从图上可以看出，Transformer的训练过程和推理过程主要有以下几点异同：\n",
    "\n",
    "1. **源输入src相同**：对于Transformer的inputs部分(src参数)一样，都是要被翻译的句子。\n",
    "2. **目标输入tgt不同**：在Transformer推理时，tgt是从`<bos>`开始，然后每次加入上一次的输出（第二次输入为`<bos> 我`）。但在训练时是一次将“完整”的结果给到Transformer，这样其实和一个一个给结果上一致（可参考[该篇](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)的Mask Attention部分）。这里还有一个细节，就是tgt比src少了一位，src是7个token，而tgt是6个token。这是因为我们在最后一次推理时，只会传入前n-1个token。举个例子：假设我们要预测`<bos> 我 爱 你 <eos>`（这里忽略pad），我们最后一次的输入tgt是`<bos> 我 爱 你`（没有`<eos>`），因此我们的输入tgt一定不会出现目标的最后一个token，所以一般tgt处理时会将目标句子删掉最后一个token。\n",
    "3. **输出数量变多**：在训练时，transformer会一次输出多个概率分布。例如上图，`我`就的等价于是tgt为`<bos>`时的输出，`爱`就等价于tgt为`<bos> 我`时的输出，依次类推。当然在训练时，得到输出概率分布后就可以计算loss了，并不需要将概率分布再转成对应的文字。注意这里也有个细节，我们的输出数量是6，对应到token就是`我 爱 你 <eos> <pad> <pad>`，这里少的是`<bos>`，因为`<bos>`不需要预测。计算loss时，我们也是要和的这几个token进行计算，所以我们的label不包含`<bos>`。代码中通常命名为`tgt_y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "当得到transformer的输出后，我们就可以计算loss了，计算过程如图：\n",
    "\n",
    "<img src=\"./images/transformer_loss.png\" width=500>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pytorch中的nn.Transformer\n",
    "\n",
    "## nn.Transformer简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在Pytorch中已经为我们实现了Transformer，我们可以直接拿来用，但nn.Transformer和我们上图的还是有点区别，具体如图：\n",
    "\n",
    "<img src=\"./images/transformer_5.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Transformer并没有实现`Embedding`和`Positional Encoding`和最后的`Linear+Softmax`部分，这里我简单对这几部分进行说明：\n",
    "\n",
    "- **Embedding**: 负责将token映射成高维向量。例如将123映射成`[0.34, 0.45, 0.123, ..., 0.33]`。通常使用`nn.Embedding`来实现。但`nn.Embedding`**的参数并不是一成不变的，也是会参与梯度下降**。关于`nn.Embedding`可参考文章[Pytorch nn.Embedding的基本使用](https://blog.csdn.net/zhaohongfei_358/article/details/122809709)\n",
    "- **Positional Encoding**：位置编码。用于为token编码增加位置信息，例如`I love you`这三个token编码后的向量并不包含其位置信息(love左边是I，右边是you这个信息)。这个位置信息还挺重要的，有和没有真的是天差地别。\n",
    "- **Linear+Softmax**：一个线性层加一个Softmax，用于对nn.Transformer输出的结果进行token预测。如果把Transformer比作CNN，那么nn.Transformer实现的就是卷积层，而`Linear+Softmax`就是卷积层后面的线性层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里我先简单的演示一下`nn.Transformer`的使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义编码器，词典大小为10，要把token编码成128维的向量\n",
    "embedding = nn.Embedding(10, 128)\n",
    "# 定义transformer，模型维度为128（也就是词向量的维度）\n",
    "transformer = nn.Transformer(d_model=128, batch_first=True) # batch_first一定不要忘记\n",
    "# 定义源句子，可以想想成是 <bos> 我 爱 吃 肉 和 菜 <eos> <pad> <pad>\n",
    "src = torch.LongTensor([[0, 3, 4, 5, 6, 7, 8, 1, 2, 2]])\n",
    "# 定义目标句子，可以想想是 <bos> I like eat meat and vegetables <eos> <pad>\n",
    "tgt = torch.LongTensor([[0, 3, 4, 5, 6, 7, 8, 1, 2]])\n",
    "# 将token编码后送给transformer（这里暂时不加Positional Encoding）\n",
    "outputs = transformer(embedding(src), embedding(tgt))\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Transformer输出的Shape和tgt编码后的Shape一致。在训练时，我们会把transformer的所有输出送给Linear，而在推理时，只需要将最后一个输出送给Linear即可，即`outputs[:, -1]`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## nn.Transformer的构造参数详解\n",
    "\n",
    "Transformer构造参数众多，所以我们还需要将黑盒稍微打开一下：\n",
    "\n",
    "<img src=\"./images/transformer_6.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "nn.Transformer主要由两部分构成：`nn.TransformerEncoder`和`nn.TransformerDecoder`。而`nn.TransformerEncoder`又是由多个`nn.TransformerEncoderLayer`堆叠而成的，图中的`Nx`就是要堆叠多少层。`nn.TransformerDecoder`同理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "下面是nn.Transformer的构造参数：\n",
    "\n",
    "- **d_model**: Encoder和Decoder输入参数的特征维度。也就是词向量的维度。默认为512\n",
    "- **nhead**: 多头注意力机制中，head的数量。关于Attention机制，可以参考[这篇文章](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)。注意该值并不影响网络的深度和参数数量。默认值为8。\n",
    "- **num_encoder_layers**: TransformerEncoderLayer的数量。该值越大，网络越深，网络参数量越多，计算量越大。默认值为6\n",
    "- **num_decoder_layers**：TransformerDecoderLayer的数量。该值越大，网络越深，网络参数量越多，计算量越大。默认值为6\n",
    "- **dim_feedforward**：Feed Forward层（Attention后面的全连接网络）的隐藏层的神经元数量。该值越大，网络参数量越多，计算量越大。默认值为2048\n",
    "- **dropout**：dropout值。默认值为0.1\n",
    "- **activation**： Feed Forward层的激活函数。取值可以是string(“relu” or “gelu”)或者一个一元可调用的函数。默认值是relu\n",
    "- **custom_encoder**：自定义Encoder。若你不想用官方实现的TransformerEncoder，你可以自己实现一个。默认值为None\n",
    "- **custom_decoder**: 自定义Decoder。若你不想用官方实现的TransformerDecoder，你可以自己实现一个。\n",
    "- **layer_norm_eps**: `Add&Norm`层中，BatchNorm的eps参数值。默认为1e-5\n",
    "- **batch_first**：batch维度是否是第一个。如果为True，则输入的shape应为(batch_size, 词数，词向量维度)，否则应为(词数, batch_size, 词向量维度)。默认为False。**这个要特别注意，因为大部分人的习惯都是将batch_size放在最前面，而这个参数的默认值又是False，所以会报错**。\n",
    "- **norm_first** – 是否要先执行norm。例如，在图中的执行顺序为 `Attention -> Add -> Norm`。若该值为True，则执行顺序变为：`Norm -> Attention -> Add`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transformer的forward参数详解\n",
    "\n",
    "Transformer的forward参数需要详细解释，这里我先将其列出来，进行粗略解释，然后再逐个进行详细解释：\n",
    "\n",
    "- **src**: Encoder的输入。也就是将token进行Embedding并Positional Encoding之后的tensor。**必填参数**。**Shape为(batch_size, 词数, 词向量维度)**\n",
    "- **tgt**: 与src同理，Decoder的输入。 **必填参数**。**Shape为(batch_size, 词数, 词向量维度)**\n",
    "- **src_mask**: 对src进行mask。**不常用**。**Shape为(词数, 词数)**\n",
    "- **tgt_mask**：对tgt进行mask。**常用**。**Shape为(词数, 词数)**\n",
    "- **memory_mask** – 对Encoder的输出memory进行mask。 **不常用**。**Shape为(batch_size, 词数, 词数)**\n",
    "- **src_key_padding_mask**：对src的token进行mask. **常用**。**Shape为(batch_size, 词数)**\n",
    "- **tgt_key_padding_mask**：对tgt的token进行mask。**常用**。**Shape为(batch_size, 词数)**\n",
    "- **memory_key_padding_mask**：对tgt的token进行mask。**不常用**。**Shape为(batch_size, 词数)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> 上面的所有mask都是`0`代表不遮掩，`-inf`代表遮掩。严禁用`True`和`False`，虽然看起来它们可以用，但是部分场景下会让输出变为`nan`。另外，src_mask、tgt_mask和memory_mask是不需要传batch的\n",
    "\n",
    "\n",
    "上面说了和没说其实差不多，重要的是每个参数的是否常用和其对应的Shape（这里我默认`batch_first=True`）。 接下来对各个参数进行详细解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### src和tgt\n",
    "\n",
    "src参数和tgt参数分别为Encoder和Decoder的输入参数。它们是对token进行编码后，再经过Positional Encoding之后的结果。\n",
    "\n",
    "例如：我们一开始的输入为：`[[0, 3, 4, 5, 6, 7, 8, 1, 2, 2]]`，Shape为(1, 10)，表示batch_size为1, 每句10个词。\n",
    "\n",
    "在经过Embedding后，Shape就变成了(1, 10, 128)，表示batch_size为1, 每句10个词，每个词被编码为了128维的向量。\n",
    "\n",
    "src就是这个(1, 10, 128)的向量。tgt同理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### src_mask、tgt_mask和memory_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "要真正理解mask，需要学习Attention机制，可参考[该篇](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)。这里只做一个简要的说明。\n",
    "\n",
    "在经过Attention层时，会让每个词具有上下文关系，也就是每个词除了自己的信息外，还包含其他词的信息。例如：`苹果 很 好吃`和`苹果 手机 很 好玩`，这两个`苹果`显然指的不是同一个意思。但让`苹果`这个词具备了后面`好吃`或`手机`这两个词的信息后，那就可以区分这两个`苹果`的含义了。\n",
    "\n",
    "在Attention中，我们有这么一个“方阵”，描述着词与词之间的关系，例如：\n",
    "\n",
    "```\n",
    "       苹果  很  好吃\n",
    "苹果 [[0.5, 0.1, 0.4],\n",
    "很    [0.1, 0.8, 0.1],\n",
    "好吃  [0.3, 0.1, 0.6],]\n",
    "```\n",
    "\n",
    "在上述矩阵中，`苹果`这个词与自身, `很`和`好吃`三个词的关系权重就是`[0.5, 0.1, 0.4]`，通过该矩阵，我们就可以得到包含上下文的`苹果`了，即\n",
    "\n",
    "$$\n",
    "\\text{苹果}' = \\text{苹果}\\times 0.5 + \\text{很} \\times 0.1 + \\text{好吃} \\times 0.4\n",
    "$$\n",
    "\n",
    "但在实际推理时，词是一个一个输出的。若`苹果很好吃`是tgt的话，那么`苹果`是不应该包含`很`和`好吃`的上下文信息的，所以我们希望为：\n",
    "\n",
    "$$\n",
    "\\text{苹果}' = \\text{苹果}\\times 0.5\n",
    "$$\n",
    "\n",
    "同理，`很`字可以包含`苹果`的上下信息，但不能包含`好吃`，所以为：\n",
    "\n",
    "$$\n",
    "\\text{很}' = \\text{苹果}\\times 0.1 + \\text{很} \\times 0.8\n",
    "$$\n",
    "\n",
    "那要完成这个事情，那只需要改变方阵即可：\n",
    "\n",
    "```\n",
    "       苹果  很  好吃\n",
    "苹果 [[0.5, 0,   0],\n",
    "很    [0.1, 0.8, 0],\n",
    "好吃  [0.3, 0.1, 0.6],]\n",
    "```\n",
    "\n",
    "而这个事情我们就可以使用mask掩码来完成，即：\n",
    "\n",
    "```\n",
    "       苹果   很    好吃\n",
    "苹果 [[ 0,  -inf, -inf],\n",
    "很    [ 0,   0,   -inf],\n",
    "好吃  [ 0,   0,    0]]\n",
    "```\n",
    "\n",
    "其中0表示不遮掩，而`-inf`表示遮掩。（之所以这么定是因为这个方阵还要过softmax，所以会使`-inf`变为0）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "所以，对于tgt\\_mask，我们只需要生成一个斜着覆盖的方阵即可，我们可以利用`nn.Transformer.generate_square_subsequent_mask`来完成，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Transformer.generate_square_subsequent_mask(5) # 这个5指的是tgt的token的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "通过上面的分析，src和memory一般是不需要进行mask的，所以不常用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### key_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在我们的src和tgt语句中，除了本身的词外，还包含了三种token: `<bos>`, `<eos>` 和 `<pad>`。这里面的`<pad>`只是为了改变句子长度，方便将不同长度的句子组成batch而进行填充的。该token没有任何意义，所以在计算Attention时，也不想让它们参与，所以也要mask。而对于这种mask就需要用到key_padding_mask这个参数了。\n",
    "\n",
    "例如，我们的src为`[[0, 3, 4, 5, 6, 7, 8, 1, 2, 2]]`，其中2是`<pad>`，所以我们的`src_key_padding_mask`就应为`[[0, 0, 0, 0, 0, 0, 0, 0, -inf, -inf]]`，即将最后两个2给掩盖住。\n",
    "\n",
    "`tgt_key_padding_mask`同理。但`memory_key_padding_mask`就没有必要用了。\n",
    "\n",
    "> 在Transformer的源码中或其他实现中，tgt_mask和tgt_key_padding_mask是合在一起的，例如：\n",
    "```\n",
    "[[0., -inf, -inf, -inf],  # tgt_mask\n",
    " [0., 0., -inf, -inf],\n",
    " [0., 0., 0., -inf],\n",
    " [0., 0., 0., 0.]]\n",
    " +\n",
    " [[0., 0., 0., -inf]]  # tgt_key_padding_mask\n",
    " =\n",
    "[[0., -inf, -inf, -inf],  # 合并之后的\n",
    " [0., 0., -inf, -inf],\n",
    " [0., 0., 0., -inf],\n",
    " [0., 0., 0., -inf]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## nn.Transformer的使用\n",
    "\n",
    "接下来我们来简单的使用一下`nn.Transformer`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "首先我们定义src和tgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "src = torch.LongTensor([\n",
    "    [0, 8, 3, 5, 5, 9, 6, 1, 2, 2, 2],\n",
    "    [0, 6, 6, 8, 9, 1 ,2, 2, 2, 2, 2],\n",
    "])\n",
    "tgt = torch.LongTensor([\n",
    "    [0, 8, 3, 5, 5, 9, 6, 1, 2, 2],\n",
    "    [0, 6, 6, 8, 9, 1 ,2, 2, 2, 2],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "接下来定义一个辅助函数来生成src_key_padding_mask和tgt_key_padding_mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf]])\n"
     ]
    }
   ],
   "source": [
    "def get_key_padding_mask(tokens):\n",
    "    key_padding_mask = torch.zeros(tokens.size())\n",
    "    key_padding_mask[tokens == 2] = -torch.inf\n",
    "    return key_padding_mask\n",
    "\n",
    "src_key_padding_mask = get_key_padding_mask(src)\n",
    "tgt_key_padding_mask = get_key_padding_mask(tgt)\n",
    "print(tgt_key_padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "然后通过Transformer内容方法生成`tgt_mask`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(-1))\n",
    "print(tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "之后就可以定义Embedding和Transformer进行调用了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "# 定义编码器，词典大小为10，要把token编码成128维的向量\n",
    "embedding = nn.Embedding(10, 128)\n",
    "# 定义transformer，模型维度为128（也就是词向量的维度）\n",
    "transformer = nn.Transformer(d_model=128, batch_first=True) # batch_first一定不要忘记\n",
    "# 将token编码后送给transformer（这里暂时不加Positional Encoding）\n",
    "outputs = transformer(embedding(src), embedding(tgt),\n",
    "                      tgt_mask=tgt_mask,\n",
    "                      src_key_padding_mask=src_key_padding_mask,\n",
    "                      tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "print(outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 实战：使用nn.Transformer实现一个简单的Copy任务\n",
    "\n",
    "任务描述：让Transformer预测输入。例如，输入为`[0, 3, 4, 6, 7, 1, 2, 2]`，则期望的输出为`[0, 3, 4, 6, 7, 1]`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "首先，我们定义一下句子的最大长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_length=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "定义PositionEncoding类，不需要知道具体什么意思，直接拿过来用即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 初始化Shape为(max_len, d_model)的PE (positional encoding)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # 初始化一个tensor [[0, 1, 2, 3, ...]]\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # 这里就是sin和cos括号中的内容，通过e和ln进行了变换\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        # 计算PE(pos, 2i)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算PE(pos, 2i+1)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 为了方便计算，在最外面在unsqueeze出一个batch\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 如果一个参数不参与梯度下降，但又希望保存model的时候将其保存下来\n",
    "        # 这个时候就可以用register_buffer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x 为embedding后的inputs，例如(1,7, 128)，batch size为1,7个单词，单词维度为128\n",
    "        \"\"\"\n",
    "        # 将x和positional encoding相加。\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "定义我们的Copy模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CopyTaskModel(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=128):\n",
    "        super(CopyTaskModel, self).__init__()\n",
    "\n",
    "        # 定义词向量，词典数为10。我们不预测两位小数。\n",
    "        self.embedding = nn.Embedding(num_embeddings=10, embedding_dim=128)\n",
    "        # 定义Transformer。超参是我拍脑袋想的\n",
    "        self.transformer = nn.Transformer(d_model=128, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=512, batch_first=True)\n",
    "\n",
    "        # 定义位置编码器\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=0)\n",
    "\n",
    "        # 定义最后的线性层，这里并没有用Softmax，因为没必要。\n",
    "        # 因为后面的CrossEntropyLoss中自带了\n",
    "        self.predictor = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 生成mask\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size()[-1])\n",
    "        src_key_padding_mask = CopyTaskModel.get_key_padding_mask(src)\n",
    "        tgt_key_padding_mask = CopyTaskModel.get_key_padding_mask(tgt)\n",
    "\n",
    "        # 对src和tgt进行编码\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "        # 给src和tgt的token增加位置信息\n",
    "        src = self.positional_encoding(src)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        # 将准备好的数据送给transformer\n",
    "        out = self.transformer(src, tgt,\n",
    "                               tgt_mask=tgt_mask,\n",
    "                               src_key_padding_mask=src_key_padding_mask,\n",
    "                               tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "        \"\"\"\n",
    "        这里直接返回transformer的结果。因为训练和推理时的行为不一样，\n",
    "        所以在该模型外再进行线性层的预测。\n",
    "        \"\"\"\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_padding_mask(tokens):\n",
    "        \"\"\"\n",
    "        用于key_padding_mask\n",
    "        \"\"\"\n",
    "        key_padding_mask = torch.zeros(tokens.size())\n",
    "        key_padding_mask[tokens == 2] = -torch.inf\n",
    "        return key_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = CopyTaskModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里简单的尝试下我们定义的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 128])\n",
      "tensor([[[ 3.6808e-01,  5.5695e-02,  3.1112e-01, -1.3590e+00, -2.2056e+00,\n",
      "           8.2623e-01, -5.9647e-01,  7.2865e-01,  1.1107e+00,  3.1777e-01,\n",
      "           9.3327e-01,  1.6467e+00,  2.9005e-01, -6.1743e-02, -1.2671e+00,\n",
      "           9.7762e-04, -4.2245e-01,  1.3059e+00, -2.2860e-01, -3.5050e-01,\n",
      "           7.7894e-01,  6.4178e-01, -1.1824e-01, -1.1628e+00, -1.1081e+00,\n",
      "          -1.0067e-01, -1.4511e+00,  1.7793e+00,  1.0915e+00,  3.3269e-01,\n",
      "          -1.8409e+00, -1.1719e+00, -4.1717e-01,  8.9506e-01, -2.8423e-01,\n",
      "          -9.1615e-01,  1.0092e+00, -7.9152e-01,  1.4280e+00, -2.0266e-01,\n",
      "          -3.2017e-01, -6.3326e-01,  6.8759e-01,  5.6735e-01,  6.6226e-01,\n",
      "          -1.3127e+00, -2.7369e-01,  7.0019e-01, -9.7401e-01, -4.3914e-02,\n",
      "          -6.5255e-01,  5.4632e-01,  6.3239e-02,  1.4105e+00, -7.6328e-01,\n",
      "           2.9785e-01,  1.6924e-01,  3.5187e-01,  1.4048e+00,  6.3786e-03,\n",
      "           9.1983e-02,  1.3994e+00, -1.2437e+00, -3.5871e-01, -4.5441e-02,\n",
      "           1.4487e+00,  2.2036e-01,  1.4141e+00,  6.6192e-01, -1.4309e+00,\n",
      "           1.4953e+00, -1.8790e+00, -4.8295e-01, -2.4120e-01,  8.9743e-01,\n",
      "          -3.9673e-01, -1.4896e+00,  5.8330e-01, -9.4708e-01,  1.4174e-01,\n",
      "           2.1209e-02,  2.2687e+00,  9.7855e-01,  9.8292e-01,  2.8544e-01,\n",
      "           6.7705e-01, -1.4959e+00, -1.2229e+00,  2.7203e-01,  5.2138e-02,\n",
      "          -2.3083e-01, -1.1773e+00, -9.2967e-01,  6.4744e-02,  1.8750e-01,\n",
      "          -1.3340e+00, -2.5763e+00,  3.5869e-01,  1.5905e+00,  1.9536e+00,\n",
      "           1.0794e+00,  1.7503e-01, -1.3948e+00, -4.0067e-01, -1.2215e+00,\n",
      "          -1.5425e-01, -9.0188e-01,  1.1568e+00,  4.8435e-01, -1.5573e+00,\n",
      "          -1.2948e+00,  8.6331e-01, -5.4970e-01,  3.7149e-01, -1.2827e+00,\n",
      "           1.8161e+00, -2.0962e+00,  1.3429e+00, -4.4632e-02,  3.2899e-02,\n",
      "           3.7434e-01,  1.6920e+00, -5.2212e-01, -1.3969e-01, -7.3668e-01,\n",
      "           1.0342e+00, -1.1114e+00,  7.3148e-01],\n",
      "         [ 2.8406e-01, -4.6810e-01, -3.6070e-01,  2.5544e-01, -1.5476e+00,\n",
      "          -9.1013e-01, -5.0037e-01,  5.3668e-01,  4.9447e-01,  5.2618e-02,\n",
      "           4.8724e-01,  1.0599e+00,  1.2758e+00,  1.0918e+00, -2.4453e-01,\n",
      "           1.8147e-01, -2.8086e-01,  1.7455e+00,  7.2922e-01, -1.1734e-01,\n",
      "           3.9276e-01,  1.3774e+00, -6.0002e-01, -5.2240e-01, -1.0215e+00,\n",
      "          -4.5083e-01, -6.8498e-01,  1.4089e+00,  2.1039e-01,  1.5689e+00,\n",
      "          -1.7089e+00, -1.6138e-02,  4.8872e-01,  4.9732e-01, -1.8855e+00,\n",
      "           2.9773e-01, -8.6200e-01, -8.1630e-02, -5.5731e-01, -4.9790e-01,\n",
      "          -3.2184e-01, -3.5576e-01,  1.0979e+00,  2.4972e+00,  9.1847e-01,\n",
      "          -7.6561e-01, -1.2746e+00,  3.6704e-01, -1.0826e+00,  1.4433e+00,\n",
      "          -9.6420e-01, -3.9009e-01,  3.5101e-01,  4.3413e-01, -1.0611e+00,\n",
      "           4.7599e-01,  1.1193e+00,  3.9660e-01,  6.5530e-02, -5.6163e-01,\n",
      "          -2.1295e-01,  1.7208e+00, -9.3455e-01, -1.0847e+00,  6.2238e-01,\n",
      "           8.9161e-01, -4.7625e-01,  8.5842e-01,  1.2397e+00, -1.0328e+00,\n",
      "          -3.1893e-01, -1.8117e+00,  8.1871e-01,  3.8944e-01,  1.2302e+00,\n",
      "          -9.0389e-01, -5.0610e-01,  6.4139e-01, -8.4137e-01,  6.6667e-01,\n",
      "           9.5616e-01,  8.4783e-01,  1.1895e-01,  1.9174e-02,  4.3648e-01,\n",
      "          -5.6108e-01, -1.0691e+00, -1.9043e+00,  1.0407e+00, -4.1921e-01,\n",
      "          -6.1342e-01,  1.6312e-01, -1.9821e+00,  6.6016e-01,  2.1263e+00,\n",
      "          -4.8328e-01, -1.0389e+00, -4.1027e-01,  1.7207e+00,  1.8933e+00,\n",
      "          -7.2343e-01,  9.3267e-02, -1.9644e+00, -2.9074e-01, -8.1626e-01,\n",
      "          -4.5985e-03, -1.1664e+00,  5.1068e-01,  4.2072e-01, -7.6729e-01,\n",
      "          -2.5414e+00,  6.7419e-01, -6.6012e-01,  5.4723e-04, -1.2716e+00,\n",
      "           2.0434e+00, -2.0767e+00,  2.0503e+00, -8.8106e-01, -1.8661e-01,\n",
      "           1.4956e+00, -3.8987e-01, -2.7962e-01,  5.4403e-01,  6.1275e-01,\n",
      "           6.7690e-01, -1.5047e+00,  4.3859e-01],\n",
      "         [ 5.0810e-01, -2.2860e-01, -4.0179e-01, -6.9287e-01, -1.0375e+00,\n",
      "          -1.1296e+00,  8.6704e-01, -1.0288e+00, -2.5569e-01,  7.9908e-01,\n",
      "          -2.6558e-01, -9.5181e-01,  6.7945e-01, -1.5437e+00, -4.1562e-01,\n",
      "           1.2404e+00,  4.5129e-01,  1.2508e+00,  8.9563e-01, -5.4881e-01,\n",
      "           4.1076e-01,  1.1582e+00, -3.8839e-01, -1.2223e+00, -2.6154e-02,\n",
      "           2.3017e-02, -2.1673e-01,  4.0256e-01,  2.5761e-01,  8.6792e-01,\n",
      "          -1.0185e+00, -6.1696e-01,  4.0940e-01,  1.6915e+00, -1.5437e+00,\n",
      "          -1.1395e+00,  7.2707e-01,  1.0629e+00,  7.6668e-01, -4.2702e-02,\n",
      "           8.5077e-01, -1.8798e+00,  2.5987e-01,  1.2520e+00, -4.0995e-01,\n",
      "          -3.7584e-01, -4.2232e-01,  4.7968e-01, -8.8201e-02,  5.7175e-01,\n",
      "           6.2665e-01,  9.3234e-01,  4.5398e-01,  7.6639e-01, -6.2112e-01,\n",
      "           4.6493e-01,  1.1619e+00, -2.1496e-01, -2.8210e-02, -9.5271e-01,\n",
      "           1.4229e-01,  1.4687e+00, -8.0346e-01,  3.6649e-01,  8.0978e-01,\n",
      "           1.1329e+00,  7.9686e-01,  8.1847e-01,  1.4428e+00, -2.1591e+00,\n",
      "          -7.0994e-01, -8.7920e-01,  7.2785e-01, -8.3010e-01,  2.0413e-01,\n",
      "          -6.8859e-01, -8.8885e-01,  3.9043e-01, -7.4427e-01,  1.5470e+00,\n",
      "           1.3406e+00,  4.2089e-01,  6.2185e-02,  1.9038e+00,  1.0277e+00,\n",
      "           2.5344e-01, -1.2028e+00, -1.6691e+00,  9.6213e-01, -2.1083e-01,\n",
      "           2.2567e-02, -5.0252e-01, -2.5766e+00, -1.7522e-01,  1.6847e+00,\n",
      "          -1.6271e+00, -1.0088e+00,  1.0280e+00,  2.6268e-01,  1.0836e+00,\n",
      "          -8.9347e-01, -1.2062e+00, -1.1599e+00, -4.3802e-01, -1.4121e+00,\n",
      "           1.1233e+00,  4.8231e-01,  5.3306e-01,  5.9372e-01, -1.5573e+00,\n",
      "          -2.2153e+00,  5.4795e-01, -3.4957e-01, -5.7876e-01, -2.3615e+00,\n",
      "           2.8392e+00, -2.2986e+00,  9.4124e-01, -2.2553e-01,  2.6656e-01,\n",
      "           4.3288e-01,  8.6296e-01,  7.9726e-01, -7.2764e-01, -6.1256e-01,\n",
      "          -4.3125e-01,  1.4922e-01,  1.0931e+00],\n",
      "         [ 2.8981e-01, -4.1585e-01, -4.5004e-01, -1.6331e+00, -1.5589e+00,\n",
      "          -1.9519e+00, -4.1462e-01, -9.3625e-01,  7.2732e-01,  5.0358e-01,\n",
      "          -8.8463e-01,  6.3430e-01,  1.3238e+00, -3.1620e-01,  5.2511e-01,\n",
      "          -2.2111e-01, -8.8626e-01,  9.4491e-02,  9.1542e-01, -1.4178e-01,\n",
      "           1.4937e+00,  6.8219e-01, -9.7382e-01, -1.5485e+00, -1.1850e+00,\n",
      "          -6.7796e-01, -1.0096e+00,  2.3941e-01, -1.0169e+00,  8.3481e-01,\n",
      "          -2.0846e+00, -5.3288e-01, -1.3918e+00,  7.7391e-01, -1.1496e+00,\n",
      "           7.2688e-01, -2.2470e-01, -1.0874e+00,  7.7815e-01,  7.9181e-01,\n",
      "           1.8212e-01, -1.0181e+00,  5.7922e-01,  1.5557e+00,  1.2198e+00,\n",
      "           8.1576e-01, -4.0644e-02,  3.2335e-01, -2.9766e-01,  3.6380e-01,\n",
      "          -4.5526e-02, -1.4792e-02,  4.3497e-02,  7.0396e-01, -1.9736e-01,\n",
      "           1.4492e-01,  2.3208e-02, -6.1386e-01,  1.8308e+00,  7.7127e-02,\n",
      "           6.4372e-01,  4.9198e-01, -6.2742e-02, -7.2371e-01,  9.6194e-01,\n",
      "           1.2836e+00,  1.6791e-01,  1.7485e+00,  2.6829e-01, -2.9027e+00,\n",
      "           1.4632e-01, -3.1989e+00,  2.5777e-01, -8.9282e-01, -1.7717e+00,\n",
      "           1.1390e-01,  2.2131e-01,  9.5555e-02,  1.7667e-01,  4.2690e-01,\n",
      "           6.9767e-01,  2.4855e+00, -4.9550e-01,  8.5968e-01,  3.3021e-01,\n",
      "          -2.2393e-01, -5.5412e-02, -5.6043e-01,  4.3478e-01,  5.7909e-01,\n",
      "           4.4508e-02,  1.0422e-01, -1.9901e+00, -1.0065e-01,  6.9052e-01,\n",
      "          -1.1350e+00, -2.8108e-02,  4.0328e-02,  4.6874e-01, -3.2543e-02,\n",
      "          -2.7532e-01, -6.5002e-01, -1.1008e+00, -4.5050e-01,  1.5885e-01,\n",
      "           5.0794e-01, -2.7360e-01,  1.8289e-01,  7.4030e-01, -6.6099e-01,\n",
      "          -3.7244e-01,  1.8016e+00,  4.7654e-01, -3.0859e-01, -2.6660e+00,\n",
      "           2.4260e+00, -3.2536e-02,  2.3239e+00,  4.6421e-01, -1.9778e-01,\n",
      "           1.0736e+00,  1.8328e+00, -1.1158e+00,  5.2804e-01,  2.1783e-01,\n",
      "           1.6582e+00, -4.3596e-02, -8.6350e-02],\n",
      "         [ 1.3623e-01, -2.2365e-01, -1.1036e-02, -2.5216e+00, -1.2127e+00,\n",
      "          -1.2023e+00, -5.1186e-01,  5.5551e-01,  6.7091e-01,  5.2349e-02,\n",
      "          -1.4446e-01, -9.5017e-02,  1.7431e+00,  4.1165e-01,  1.8059e-01,\n",
      "           7.2328e-01,  5.1162e-01,  3.7239e-01,  1.7253e+00, -2.0817e-01,\n",
      "           1.5533e+00, -4.0795e-01, -6.8184e-01, -2.8642e-01, -4.8846e-01,\n",
      "          -2.1546e-01, -1.0820e+00, -8.4570e-01, -2.4971e-01,  8.5544e-01,\n",
      "          -1.9768e+00, -2.5896e-01,  2.7856e-01,  2.3290e+00, -1.6403e+00,\n",
      "           7.4138e-02,  1.5796e+00, -7.8249e-01,  4.9223e-01,  3.2672e-01,\n",
      "           4.4965e-01, -8.3284e-01,  4.5015e-01,  1.4182e+00,  4.0370e-01,\n",
      "          -1.2928e+00, -1.5063e+00,  6.4798e-01,  1.0163e-01,  4.0768e-02,\n",
      "          -7.5713e-01,  5.5878e-01, -1.6700e+00,  1.6501e-01,  3.0193e-01,\n",
      "           4.9173e-01,  9.7192e-01,  7.3237e-01,  1.0242e+00,  3.1901e-01,\n",
      "           5.2291e-01,  5.9291e-01, -2.1729e-01,  7.4935e-01,  1.1309e-01,\n",
      "           1.0008e+00,  5.8799e-01,  2.0722e+00, -1.1677e+00, -1.2049e+00,\n",
      "          -6.0796e-01, -8.5817e-01,  1.3828e-02, -8.5216e-01, -4.7139e-01,\n",
      "           4.7137e-01, -6.0611e-01,  9.3801e-01, -8.4124e-01, -5.5396e-01,\n",
      "           2.2850e+00,  8.9661e-01,  1.2763e+00,  8.2217e-01,  4.3320e-01,\n",
      "          -5.3114e-01, -1.9242e+00, -8.3428e-01,  2.4255e-02,  5.2227e-01,\n",
      "          -1.3010e+00, -7.2939e-01, -2.3753e+00, -6.0273e-01,  2.8045e-01,\n",
      "          -1.3177e-01, -1.5503e+00,  7.2829e-02,  1.6570e-01,  1.5725e+00,\n",
      "          -7.7013e-01, -9.1592e-01, -1.2059e+00,  7.7978e-02, -4.4927e-01,\n",
      "           2.3400e-01, -1.3006e+00,  1.5641e+00, -3.0102e-01, -4.3870e-01,\n",
      "          -1.9066e+00,  1.6963e+00,  1.1284e+00, -7.8131e-01, -2.5214e+00,\n",
      "           1.2903e+00, -9.7281e-01,  5.9950e-01,  2.0037e+00,  6.4099e-02,\n",
      "           1.6318e+00,  8.5800e-01, -5.1028e-01,  3.0987e-01,  7.6806e-02,\n",
      "           3.2212e-01,  1.2780e-01,  4.9349e-01],\n",
      "         [-4.1077e-01, -2.3700e-01, -1.5391e+00,  5.1931e-01, -2.7737e+00,\n",
      "          -5.2931e-01,  8.4177e-01,  6.7889e-01, -4.2498e-01,  2.9119e-01,\n",
      "          -1.0771e+00, -2.6170e-01,  1.0892e+00, -1.2869e+00,  2.3282e-01,\n",
      "          -7.6781e-01, -5.7409e-02,  7.0308e-01,  5.4042e-01,  1.3440e+00,\n",
      "           1.0477e+00,  5.3338e-01, -8.3879e-01, -4.4916e-01,  1.1314e+00,\n",
      "          -1.4482e-01, -1.2412e+00, -8.2178e-01, -2.1805e-01, -1.0797e+00,\n",
      "          -2.1663e+00, -1.2591e+00, -7.1275e-02,  6.3342e-01, -1.2141e+00,\n",
      "           1.5325e-02,  4.2612e-01,  7.5463e-01, -4.5398e-01,  3.1286e-02,\n",
      "           1.7907e-01, -1.8634e-01,  8.4448e-01,  1.4688e+00,  3.8839e-01,\n",
      "          -1.2691e+00, -1.3076e-01,  2.7392e-01, -2.5159e-01, -3.8474e-01,\n",
      "          -9.3429e-01,  4.4656e-01, -4.7645e-01,  6.4384e-01, -1.2038e-01,\n",
      "           1.1609e+00,  2.2314e-01, -7.2581e-01,  1.3544e+00,  4.8299e-01,\n",
      "           4.5976e-01,  1.6292e+00,  5.9533e-02, -1.5925e+00,  1.0562e-02,\n",
      "           7.7605e-01,  1.3145e+00,  8.2096e-01,  8.0295e-01, -1.6245e+00,\n",
      "          -7.5415e-01, -1.7595e+00,  1.9142e-01,  4.2538e-01,  1.3005e+00,\n",
      "          -5.9414e-01, -1.0857e+00,  4.8598e-01, -1.5871e+00,  3.6992e-01,\n",
      "          -1.6057e-01,  1.2206e+00,  6.3390e-01,  1.3367e+00,  1.9171e+00,\n",
      "           3.1767e-01, -6.3793e-01, -8.1579e-01,  5.7054e-01, -3.0008e-01,\n",
      "          -8.3086e-01, -1.8413e+00, -1.3671e+00, -9.1059e-01,  2.5806e+00,\n",
      "          -1.8495e-01, -2.1502e+00,  7.9522e-01, -4.5872e-01,  6.9279e-01,\n",
      "           4.1022e-02, -7.3591e-01, -1.1721e+00,  1.5407e-01, -1.0310e+00,\n",
      "           1.5209e+00,  3.1997e-02,  9.5587e-01,  1.4415e+00, -9.3848e-01,\n",
      "          -1.2207e+00,  1.1753e+00, -1.0790e-01, -3.6103e-01, -1.5788e+00,\n",
      "           1.3823e+00, -4.8486e-01,  1.6490e+00,  2.0228e-02, -1.0084e+00,\n",
      "           1.8499e+00,  1.2833e+00, -1.7743e-01,  1.3718e+00, -7.5078e-01,\n",
      "           9.0685e-01, -3.1108e-01,  1.5612e+00],\n",
      "         [ 8.6420e-01, -3.6009e-02, -2.4870e+00,  5.1531e-01, -2.7836e+00,\n",
      "          -8.8380e-02,  5.7866e-01,  7.1917e-01, -1.0233e+00,  1.2912e-01,\n",
      "          -3.4890e-01, -2.0884e-01,  7.9411e-01, -1.3892e+00, -2.9463e-01,\n",
      "          -8.3137e-01,  1.2684e-02,  8.5484e-01,  1.1835e+00,  7.2080e-01,\n",
      "           1.6107e+00,  1.0742e+00, -1.2517e+00, -8.3579e-01,  8.0586e-01,\n",
      "          -6.1489e-01, -1.3988e+00, -4.6800e-01, -3.7705e-01,  1.9304e-01,\n",
      "          -1.2681e+00,  1.3335e-01, -2.5562e-01,  5.5010e-01, -1.1573e+00,\n",
      "          -4.5232e-01,  1.0694e+00,  2.3768e-01, -5.6342e-01,  2.8956e-01,\n",
      "           5.4011e-01, -4.6782e-01,  8.1178e-01,  1.6856e+00,  3.2339e-01,\n",
      "          -1.1689e+00, -4.0915e-01,  1.8881e-01, -5.0799e-01,  3.2148e-03,\n",
      "          -1.1220e+00,  6.2341e-01,  1.9438e-02,  2.1011e-01, -5.3185e-01,\n",
      "           1.6421e+00,  9.5562e-01, -4.8312e-01,  1.0193e+00,  3.9645e-01,\n",
      "          -3.0490e-01,  1.4681e+00,  8.1868e-02, -8.3816e-01,  9.6820e-01,\n",
      "           1.4884e-01,  6.7017e-01,  8.1075e-01,  1.0039e+00, -1.3486e+00,\n",
      "          -1.0390e+00, -1.7101e+00,  2.9057e-01,  9.3930e-02, -1.0774e-01,\n",
      "          -1.2725e+00, -5.4594e-01,  9.8347e-02, -9.3577e-01,  3.7271e-01,\n",
      "           6.3956e-01,  9.8736e-01, -7.7925e-03,  2.0064e+00,  1.0090e+00,\n",
      "           1.8238e-01, -3.4231e-01, -1.1244e+00,  8.3686e-01, -7.6410e-01,\n",
      "          -5.4671e-03, -8.4645e-01, -1.6597e+00, -8.5167e-01,  2.1518e+00,\n",
      "          -1.0733e+00, -1.2479e+00, -8.5158e-02,  6.3065e-01,  1.1049e+00,\n",
      "          -4.8583e-01, -1.0741e+00, -1.4958e+00, -3.9612e-01, -6.8394e-01,\n",
      "           1.1940e+00, -2.8233e-01,  6.1024e-01,  1.9838e+00, -7.9843e-01,\n",
      "          -5.7214e-01,  8.9820e-01,  2.4126e-01, -5.5205e-01, -3.1586e+00,\n",
      "           1.1979e+00, -4.5059e-01,  1.4111e+00, -4.5932e-01, -5.0475e-01,\n",
      "           2.4755e+00,  1.9069e+00, -2.5231e-01,  9.1899e-01, -3.4397e-01,\n",
      "          -3.0795e-01, -1.5905e-01,  1.7637e+00]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src = torch.LongTensor([[0, 3, 4, 5, 6, 1, 2, 2]])\n",
    "tgt = torch.LongTensor([[3, 4, 5, 6, 1, 2, 2]])\n",
    "out = model(src, tgt)\n",
    "print(out.size())\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "没什么问题，那就接着定义损失函数和优化器，因为是多分类问题，所以用CrossEntropyLoss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "接着再定义一个生成随时数据的工具函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_batch(batch_size, max_length=16):\n",
    "    src = []\n",
    "    for i in range(batch_size):\n",
    "        # 随机生成句子长度\n",
    "        random_len = random.randint(1, max_length - 2)\n",
    "        # 随机生成句子词汇，并在开头和结尾增加<bos>和<eos>\n",
    "        random_nums = [0] + [random.randint(3, 9) for _ in range(random_len)] + [1]\n",
    "        # 如果句子长度不足max_length，进行填充\n",
    "        random_nums = random_nums + [2] * (max_length - random_len - 2)\n",
    "        src.append(random_nums)\n",
    "    src = torch.LongTensor(src)\n",
    "    # tgt不要最后一个token\n",
    "    tgt = src[:, :-1]\n",
    "    # tgt_y不要第一个的token\n",
    "    tgt_y = src[:, 1:]\n",
    "    # 计算tgt_y，即要预测的有效token的数量\n",
    "    n_tokens = (tgt_y != 2).sum()\n",
    "\n",
    "    # 这里的n_tokens指的是我们要预测的tgt_y中有多少有效的token，后面计算loss要用\n",
    "    return src, tgt, tgt_y, n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 4, 4, 4, 4, 1],\n",
       "         [0, 7, 1, 2, 2, 2]]),\n",
       " tensor([[0, 4, 4, 4, 4],\n",
       "         [0, 7, 1, 2, 2]]),\n",
       " tensor([[4, 4, 4, 4, 1],\n",
       "         [7, 1, 2, 2, 2]]),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_batch(batch_size=2, max_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " 开始进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hui/tools/anaconda3/envs/langchain_3_11/lib/python3.11/site-packages/torch/autograd/graph.py:769: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40, total_loss: 4.247206211090088\n",
      "Step 80, total_loss: 2.548478841781616\n",
      "Step 120, total_loss: 2.2841217517852783\n",
      "Step 160, total_loss: 2.168396472930908\n",
      "Step 200, total_loss: 2.13004207611084\n",
      "Step 240, total_loss: 1.9376479387283325\n",
      "Step 280, total_loss: 2.035785436630249\n",
      "Step 320, total_loss: 1.8872675895690918\n",
      "Step 360, total_loss: 1.6905711889266968\n",
      "Step 400, total_loss: 1.7015571594238281\n",
      "Step 440, total_loss: 1.6876716613769531\n",
      "Step 480, total_loss: 1.46314537525177\n",
      "Step 520, total_loss: 1.44025456905365\n",
      "Step 560, total_loss: 1.2233527898788452\n",
      "Step 600, total_loss: 1.2263368368148804\n",
      "Step 640, total_loss: 1.0708770751953125\n",
      "Step 680, total_loss: 1.310389757156372\n",
      "Step 720, total_loss: 1.0685149431228638\n",
      "Step 760, total_loss: 0.998332142829895\n",
      "Step 800, total_loss: 0.9152776002883911\n",
      "Step 840, total_loss: 0.9252691268920898\n",
      "Step 880, total_loss: 0.7330048680305481\n",
      "Step 920, total_loss: 0.7041809558868408\n",
      "Step 960, total_loss: 0.9468772411346436\n",
      "Step 1000, total_loss: 0.7472627758979797\n",
      "Step 1040, total_loss: 0.7372096180915833\n",
      "Step 1080, total_loss: 0.7068101167678833\n",
      "Step 1120, total_loss: 0.6324511170387268\n",
      "Step 1160, total_loss: 0.5907240509986877\n",
      "Step 1200, total_loss: 0.6319612860679626\n",
      "Step 1240, total_loss: 0.4680973291397095\n",
      "Step 1280, total_loss: 0.626297652721405\n",
      "Step 1320, total_loss: 0.48392346501350403\n",
      "Step 1360, total_loss: 0.5620557069778442\n",
      "Step 1400, total_loss: 0.5099866986274719\n",
      "Step 1440, total_loss: 0.5185683965682983\n",
      "Step 1480, total_loss: 0.43209004402160645\n",
      "Step 1520, total_loss: 0.5165778398513794\n",
      "Step 1560, total_loss: 0.402131587266922\n",
      "Step 1600, total_loss: 0.3280286192893982\n",
      "Step 1640, total_loss: 0.3306702673435211\n",
      "Step 1680, total_loss: 0.3656400442123413\n",
      "Step 1720, total_loss: 0.5199697017669678\n",
      "Step 1760, total_loss: 0.3389662802219391\n",
      "Step 1800, total_loss: 0.32059741020202637\n",
      "Step 1840, total_loss: 0.24781817197799683\n",
      "Step 1880, total_loss: 0.3494974970817566\n",
      "Step 1920, total_loss: 0.3293145000934601\n",
      "Step 1960, total_loss: 0.3921000063419342\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "for step in range(2000):\n",
    "    # 生成数据\n",
    "    src, tgt, tgt_y, n_tokens = generate_random_batch(batch_size=2, max_length=max_length)\n",
    "\n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "    # 进行transformer的计算\n",
    "    out = model(src, tgt)\n",
    "    # 将结果送给最后的线性层进行预测\n",
    "    out = model.predictor(out)\n",
    "    \"\"\"\n",
    "    计算损失。由于训练时我们的是对所有的输出都进行预测，所以需要对out进行reshape一下。\n",
    "            我们的out的Shape为(batch_size, 词数, 词典大小)，view之后变为：\n",
    "            (batch_size*词数, 词典大小)。\n",
    "            而在这些预测结果中，我们只需要对非<pad>部分进行，所以需要进行正则化。也就是\n",
    "            除以n_tokens。\n",
    "    \"\"\"\n",
    "    loss = criteria(out.contiguous().view(-1, out.size(-1)), tgt_y.contiguous().view(-1)) / n_tokens\n",
    "    # 计算梯度\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss\n",
    "\n",
    "    # 每40次打印一下loss\n",
    "    if step != 0 and step % 40 == 0:\n",
    "        print(\"Step {}, total_loss: {}\".format(step, total_loss))\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在完成模型训练后，我们来使用一下我们的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "# 随便定义一个src\n",
    "src = torch.LongTensor([[0, 4, 3, 4, 6, 8, 9, 9, 8, 1, 2, 2]])\n",
    "# tgt从<bos>开始，看看能不能重新输出src中的值\n",
    "tgt = torch.LongTensor([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 4, 3, 4, 6, 8, 9, 9, 8, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 一个一个词预测，直到预测为<eos>，或者达到句子最大长度\n",
    "for i in range(max_length):\n",
    "    # 进行transformer计算\n",
    "    out = model(src, tgt)\n",
    "    # 预测结果，因为只需要看最后一个词，所以取`out[:, -1]`\n",
    "    predict = model.predictor(out[:, -1])\n",
    "    # 找出最大值的index\n",
    "    y = torch.argmax(predict, dim=1)\n",
    "    # 和之前的预测结果拼接到一起\n",
    "    tgt = torch.concat([tgt, y.unsqueeze(0)], dim=1)\n",
    "\n",
    "    # 如果为<eos>，说明预测结束，跳出循环\n",
    "    if y == 1:\n",
    "        break\n",
    "print(tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "可以看到，我们的模型成功预测了src的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "# 参考资料：\n",
    "\n",
    "[nn.Transformer官方文档](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html): https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "[层层剖析，让你彻底搞懂Self-Attention、MultiHead-Attention和Masked-Attention的机制和原理](https://blog.csdn.net/zhaohongfei_358/article/details/122861751): https://blog.csdn.net/zhaohongfei_358/article/details/122861751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_3_11]",
   "language": "python",
   "name": "conda-env-langchain_3_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
