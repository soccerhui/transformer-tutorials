{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch中 nn.Transformer的使用详解与Transformer的黑盒讲解"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 本文内容"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformer是个相对复杂的模型，可能有些人和我一样，学了也不会用，或者感觉自己懂了，但又不懂。本文将Transformer看做一个黑盒，然后讲解Pytorch中nn.Transformer的使用。\n",
    "\n",
    "本文包含内容如下：\n",
    "\n",
    "1. Transformer的训练过程讲解\n",
    "2. Transformer的推理过程讲解\n",
    "3. Transformer的入参和出参讲解\n",
    "4. nn.Transformer的各个参数讲解\n",
    "5. nn.Transformer的mask机制详解\n",
    "6. 实战：使用nn.Transformer训练一个copy任务。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "开始之前，我们先导入要用到的包："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 将Transformer看成黑盒\n",
    "\n",
    "这是一张经典的Transformer模型图：\n",
    "\n",
    "<img src=\"./images/transformer.png\" width=\"300\">\n",
    "\n",
    "\n",
    "我们现在将其变成黑盒，将其盖住：\n",
    "\n",
    "<img src=\"./images/transformer_1.png\" width=\"300\">\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们现在再来看下Transformer的输入和输出：\n",
    "\n",
    "<img src=\"./images/transformer_2.jpg\" width=\"500\">\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里是一个翻译任务中transformer的输入和输出。transformer的输入包含两部分：\n",
    "\n",
    "- inputs: 原句子对应的tokens，且是完整句子。一般0表示句子开始(`<bos>`)，1表示句子结束(`<eos>`)，2为填充(`<pad>`)。填充的目的是为了让不同长度的句子变为同一个长度，这样才可以组成一个batch。在代码中，该变量一般取名**src**。\n",
    "- outputs(shifted right)：上一个阶段的输出。虽然名字叫outputs，但是它是输入。最开始为0（`<bos>`），然后本次预测出“我”后，下次调用Transformer的该输入就变成`<bos> 我`。在代码中，该变量一般取名**tgt**。\n",
    "\n",
    "Transformer的输出是一个概率分布。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer的推理过程\n",
    "\n",
    "这里先讲Transformer的推理过程，因为这个简单。其实通过上面的讲解，你可能已经清楚了。上面是Transformer推理的第一步，紧接着第二步如图：\n",
    "\n",
    "<img src=\"./images/transformer_3.jpg\" width=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "Transformer的推理过程就是这样一遍一遍调用Transformer，直到输出`<eos>`或达到句子最大长度为止。\n",
    "\n",
    "\n",
    "> 通常真正在实战时，Transformer的Encoder部分只需要执行一遍就行了，这里为了简单起见，就整体重新执行。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer的训练过程\n",
    "\n",
    "在Transformer推理时，我们是一个词一个词的输出，但在训练时这样做效率太低了，所以我们会将target一次性给到Transformer（当然，你也可以按照推理过程做），如图所示：\n",
    "\n",
    "<img src=\"./images/transformer_4.png\" width=\"500\">\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从图上可以看出，Transformer的训练过程和推理过程主要有以下几点异同：\n",
    "\n",
    "1. **源输入src相同**：对于Transformer的inputs部分(src参数)一样，都是要被翻译的句子。\n",
    "2. **目标输入tgt不同**：在Transformer推理时，tgt是从`<bos>`开始，然后每次加入上一次的输出（第二次输入为`<bos> 我`）。但在训练时是一次将“完整”的结果给到Transformer，这样其实和一个一个给结果上一致（可参考[该篇](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)的Mask Attention部分）。这里还有一个细节，就是tgt比src少了一位，src是7个token，而tgt是6个token。这是因为我们在最后一次推理时，只会传入前n-1个token。举个例子：假设我们要预测`<bos> 我 爱 你 <eos>`（这里忽略pad），我们最后一次的输入tgt是`<bos> 我 爱 你`（没有`<eos>`），因此我们的输入tgt一定不会出现目标的最后一个token，所以一般tgt处理时会将目标句子删掉最后一个token。\n",
    "3. **输出数量变多**：在训练时，transformer会一次输出多个概率分布。例如上图，`我`就的等价于是tgt为`<bos>`时的输出，`爱`就等价于tgt为`<bos> 我`时的输出，依次类推。当然在训练时，得到输出概率分布后就可以计算loss了，并不需要将概率分布再转成对应的文字。注意这里也有个细节，我们的输出数量是6，对应到token就是`我 爱 你 <eos> <pad> <pad>`，这里少的是`<bos>`，因为`<bos>`不需要预测。计算loss时，我们也是要和的这几个token进行计算，所以我们的label不包含`<bos>`。代码中通常命名为`tgt_y`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "当得到transformer的输出后，我们就可以计算loss了，计算过程如图：\n",
    "\n",
    "<img src=\"./images/transformer_loss.png\" width=500>\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch中的nn.Transformer\n",
    "\n",
    "## nn.Transformer简介"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在Pytorch中已经为我们实现了Transformer，我们可以直接拿来用，但nn.Transformer和我们上图的还是有点区别，具体如图：\n",
    "\n",
    "<img src=\"./images/transformer_5.png\" width=\"300\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformer并没有实现`Embedding`和`Positional Encoding`和最后的`Linear+Softmax`部分，这里我简单对这几部分进行说明：\n",
    "\n",
    "- **Embedding**: 负责将token映射成高维向量。例如将123映射成`[0.34, 0.45, 0.123, ..., 0.33]`。通常使用`nn.Embedding`来实现。但`nn.Embedding`**的参数并不是一成不变的，也是会参与梯度下降**。关于`nn.Embedding`可参考文章[Pytorch nn.Embedding的基本使用](https://blog.csdn.net/zhaohongfei_358/article/details/122809709)\n",
    "- **Positional Encoding**：位置编码。用于为token编码增加位置信息，例如`I love you`这三个token编码后的向量并不包含其位置信息(love左边是I，右边是you这个信息)。这个位置信息还挺重要的，有和没有真的是天差地别。\n",
    "- **Linear+Softmax**：一个线性层加一个Softmax，用于对nn.Transformer输出的结果进行token预测。如果把Transformer比作CNN，那么nn.Transformer实现的就是卷积层，而`Linear+Softmax`就是卷积层后面的线性层。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里我先简单的演示一下`nn.Transformer`的使用："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 9, 128])"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义编码器，词典大小为10，要把token编码成128维的向量\n",
    "embedding = nn.Embedding(10, 128)\n",
    "# 定义transformer，模型维度为128（也就是词向量的维度）\n",
    "transformer = nn.Transformer(d_model=128, batch_first=True) # batch_first一定不要忘记\n",
    "# 定义源句子，可以想想成是 <bos> 我 爱 吃 肉 和 菜 <eos> <pad> <pad>\n",
    "src = torch.LongTensor([[0, 3, 4, 5, 6, 7, 8, 1, 2, 2]])\n",
    "# 定义目标句子，可以想想是 <bos> I like eat meat and vegetables <eos> <pad>\n",
    "tgt = torch.LongTensor([[0, 3, 4, 5, 6, 7, 8, 1, 2]])\n",
    "# 将token编码后送给transformer（这里暂时不加Positional Encoding）\n",
    "outputs = transformer(embedding(src), embedding(tgt))\n",
    "outputs.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Transformer输出的Shape和tgt编码后的Shape一致。在训练时，我们会把transformer的所有输出送给Linear，而在推理时，只需要将最后一个输出送给Linear即可，即`outputs[:, -1]`。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## nn.Transformer的构造参数详解\n",
    "\n",
    "Transformer构造参数众多，所以我们还需要将黑盒稍微打开一下：\n",
    "\n",
    "<img src=\"./images/transformer_6.png\" width=\"500\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "nn.Transformer主要由两部分构成：`nn.TransformerEncoder`和`nn.TransformerDecoder`。而`nn.TransformerEncoder`又是由多个`nn.TransformerEncoderLayer`堆叠而成的，图中的`Nx`就是要堆叠多少层。`nn.TransformerDecoder`同理。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面是nn.Transformer的构造参数：\n",
    "\n",
    "- **d_model**: Encoder和Decoder输入参数的特征维度。也就是词向量的维度。默认为512\n",
    "- **nhead**: 多头注意力机制中，head的数量。关于Attention机制，可以参考[这篇文章](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)。注意该值并不影响网络的深度和参数数量。默认值为8。\n",
    "- **num_encoder_layers**: TransformerEncoderLayer的数量。该值越大，网络越深，网络参数量越多，计算量越大。默认值为6\n",
    "- **num_decoder_layers**：TransformerDecoderLayer的数量。该值越大，网络越深，网络参数量越多，计算量越大。默认值为6\n",
    "- **dim_feedforward**：Feed Forward层（Attention后面的全连接网络）的隐藏层的神经元数量。该值越大，网络参数量越多，计算量越大。默认值为2048\n",
    "- **dropout**：dropout值。默认值为0.1\n",
    "- **activation**： Feed Forward层的激活函数。取值可以是string(“relu” or “gelu”)或者一个一元可调用的函数。默认值是relu\n",
    "- **custom_encoder**：自定义Encoder。若你不想用官方实现的TransformerEncoder，你可以自己实现一个。默认值为None\n",
    "- **custom_decoder**: 自定义Decoder。若你不想用官方实现的TransformerDecoder，你可以自己实现一个。\n",
    "- **layer_norm_eps**: `Add&Norm`层中，BatchNorm的eps参数值。默认为1e-5\n",
    "- **batch_first**：batch维度是否是第一个。如果为True，则输入的shape应为(batch_size, 词数，词向量维度)，否则应为(词数, batch_size, 词向量维度)。默认为False。**这个要特别注意，因为大部分人的习惯都是将batch_size放在最前面，而这个参数的默认值又是False，所以会报错**。\n",
    "- **norm_first** – 是否要先执行norm。例如，在图中的执行顺序为 `Attention -> Add -> Norm`。若该值为True，则执行顺序变为：`Norm -> Attention -> Add`。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer的forward参数详解\n",
    "\n",
    "Transformer的forward参数需要详细解释，这里我先将其列出来，进行粗略解释，然后再逐个进行详细解释：\n",
    "\n",
    "- **src**: Encoder的输入。也就是将token进行Embedding并Positional Encoding之后的tensor。**必填参数**。**Shape为(batch_size, 词数, 词向量维度)**\n",
    "- **tgt**: 与src同理，Decoder的输入。 **必填参数**。**Shape为(batch_size, 词数, 词向量维度)**\n",
    "- **src_mask**: 对src进行mask。**不常用**。**Shape为(词数, 词数)**\n",
    "- **tgt_mask**：对tgt进行mask。**常用**。**Shape为(词数, 词数)**\n",
    "- **memory_mask** – 对Encoder的输出memory进行mask。 **不常用**。**Shape为(batch_size, 词数, 词数)**\n",
    "- **src_key_padding_mask**：对src的token进行mask. **常用**。**Shape为(batch_size, 词数)**\n",
    "- **tgt_key_padding_mask**：对tgt的token进行mask。**常用**。**Shape为(batch_size, 词数)**\n",
    "- **memory_key_padding_mask**：对tgt的token进行mask。**不常用**。**Shape为(batch_size, 词数)**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> 上面的所有mask都是`0`代表不遮掩，`-inf`代表遮掩。严禁用`True`和`False`，虽然看起来它们可以用，但是部分场景下会让输出变为`nan`。另外，src_mask、tgt_mask和memory_mask是不需要传batch的\n",
    "\n",
    "\n",
    "上面说了和没说其实差不多，重要的是每个参数的是否常用和其对应的Shape（这里我默认`batch_first=True`）。 接下来对各个参数进行详细解释。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### src和tgt\n",
    "\n",
    "src参数和tgt参数分别为Encoder和Decoder的输入参数。它们是对token进行编码后，再经过Positional Encoding之后的结果。\n",
    "\n",
    "例如：我们一开始的输入为：`[[0, 3, 4, 5, 6, 7, 8, 1, 2, 2]]`，Shape为(1, 10)，表示batch_size为1, 每句10个词。\n",
    "\n",
    "在经过Embedding后，Shape就变成了(1, 10, 128)，表示batch_size为1, 每句10个词，每个词被编码为了128维的向量。\n",
    "\n",
    "src就是这个(1, 10, 128)的向量。tgt同理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### src_mask、tgt_mask和memory_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "要真正理解mask，需要学习Attention机制，可参考[该篇](https://blog.csdn.net/zhaohongfei_358/article/details/122861751)。这里只做一个简要的说明。\n",
    "\n",
    "在经过Attention层时，会让每个词具有上下文关系，也就是每个词除了自己的信息外，还包含其他词的信息。例如：`苹果 很 好吃`和`苹果 手机 很 好玩`，这两个`苹果`显然指的不是同一个意思。但让`苹果`这个词具备了后面`好吃`或`手机`这两个词的信息后，那就可以区分这两个`苹果`的含义了。\n",
    "\n",
    "在Attention中，我们有这么一个“方阵”，描述着词与词之间的关系，例如：\n",
    "\n",
    "```\n",
    "       苹果  很  好吃\n",
    "苹果 [[0.5, 0.1, 0.4],\n",
    "很    [0.1, 0.8, 0.1],\n",
    "好吃  [0.3, 0.1, 0.6],]\n",
    "```\n",
    "\n",
    "在上述矩阵中，`苹果`这个词与自身, `很`和`好吃`三个词的关系权重就是`[0.5, 0.1, 0.4]`，通过该矩阵，我们就可以得到包含上下文的`苹果`了，即\n",
    "\n",
    "$$\n",
    "\\text{苹果}' = \\text{苹果}\\times 0.5 + \\text{很} \\times 0.1 + \\text{好吃} \\times 0.4\n",
    "$$\n",
    "\n",
    "但在实际推理时，词是一个一个输出的。若`苹果很好吃`是tgt的话，那么`苹果`是不应该包含`很`和`好吃`的上下文信息的，所以我们希望为：\n",
    "\n",
    "$$\n",
    "\\text{苹果}' = \\text{苹果}\\times 0.5\n",
    "$$\n",
    "\n",
    "同理，`很`字可以包含`苹果`的上下信息，但不能包含`好吃`，所以为：\n",
    "\n",
    "$$\n",
    "\\text{很}' = \\text{苹果}\\times 0.1 + \\text{很} \\times 0.8\n",
    "$$\n",
    "\n",
    "那要完成这个事情，那只需要改变方阵即可：\n",
    "\n",
    "```\n",
    "       苹果  很  好吃\n",
    "苹果 [[0.5, 0,   0],\n",
    "很    [0.1, 0.8, 0],\n",
    "好吃  [0.3, 0.1, 0.6],]\n",
    "```\n",
    "\n",
    "而这个事情我们就可以使用mask掩码来完成，即：\n",
    "\n",
    "```\n",
    "       苹果   很    好吃\n",
    "苹果 [[ 0,  -inf, -inf],\n",
    "很    [ 0,   0,   -inf],\n",
    "好吃  [ 0,   0,    0]]\n",
    "```\n",
    "\n",
    "其中0表示不遮掩，而`-inf`表示遮掩。（之所以这么定是因为这个方阵还要过softmax，所以会使`-inf`变为0）。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "所以，对于tgt\\_mask，我们只需要生成一个斜着覆盖的方阵即可，我们可以利用`nn.Transformer.generate_square_subsequent_mask`来完成，例如："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., -inf, -inf, -inf, -inf],\n        [0., 0., -inf, -inf, -inf],\n        [0., 0., 0., -inf, -inf],\n        [0., 0., 0., 0., -inf],\n        [0., 0., 0., 0., 0.]])"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Transformer.generate_square_subsequent_mask(5) # 这个5指的是tgt的token的数量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过上面的分析，src和memory一般是不需要进行mask的，所以不常用。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### key_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在我们的src和tgt语句中，除了本身的词外，还包含了三种token: `<bos>`, `<eos>` 和 `<pad>`。这里面的`<pad>`只是为了改变句子长度，方便将不同长度的句子组成batch而进行填充的。该token没有任何意义，所以在计算Attention时，也不想让它们参与，所以也要mask。而对于这种mask就需要用到key_padding_mask这个参数了。\n",
    "\n",
    "例如，我们的src为`[[0, 3, 4, 5, 6, 7, 8, 1, 2, 2]]`，其中2是`<pad>`，所以我们的`src_key_padding_mask`就应为`[[0, 0, 0, 0, 0, 0, 0, 0, -inf, -inf]]`，即将最后两个2给掩盖住。\n",
    "\n",
    "`tgt_key_padding_mask`同理。但`memory_key_padding_mask`就没有必要用了。\n",
    "\n",
    "> 在Transformer的源码中或其他实现中，tgt_mask和tgt_key_padding_mask是合在一起的，例如：\n",
    "```\n",
    "[[0., -inf, -inf, -inf],  # tgt_mask\n",
    " [0., 0., -inf, -inf],\n",
    " [0., 0., 0., -inf],\n",
    " [0., 0., 0., 0.]]\n",
    " +\n",
    " [[0., 0., 0., -inf]]  # tgt_key_padding_mask\n",
    " =\n",
    "[[0., -inf, -inf, -inf],  # 合并之后的\n",
    " [0., 0., -inf, -inf],\n",
    " [0., 0., 0., -inf],\n",
    " [0., 0., 0., -inf]]\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## nn.Transformer的使用\n",
    "\n",
    "接下来我们来简单的使用一下`nn.Transformer`:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先我们定义src和tgt:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "src = torch.LongTensor([\n",
    "    [0, 8, 3, 5, 5, 9, 6, 1, 2, 2, 2],\n",
    "    [0, 6, 6, 8, 9, 1 ,2, 2, 2, 2, 2],\n",
    "])\n",
    "tgt = torch.LongTensor([\n",
    "    [0, 8, 3, 5, 5, 9, 6, 1, 2, 2],\n",
    "    [0, 6, 6, 8, 9, 1 ,2, 2, 2, 2],\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "接下来定义一个辅助函数来生成src_key_padding_mask和tgt_key_padding_mask:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf]])\n"
     ]
    }
   ],
   "source": [
    "def get_key_padding_mask(tokens):\n",
    "    key_padding_mask = torch.zeros(tokens.size())\n",
    "    key_padding_mask[tokens == 2] = -torch.inf\n",
    "    return key_padding_mask\n",
    "\n",
    "src_key_padding_mask = get_key_padding_mask(src)\n",
    "tgt_key_padding_mask = get_key_padding_mask(tgt)\n",
    "print(tgt_key_padding_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "然后通过Transformer内容方法生成`tgt_mask`："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(-1))\n",
    "print(tgt_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "之后就可以定义Embedding和Transformer进行调用了："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "# 定义编码器，词典大小为10，要把token编码成128维的向量\n",
    "embedding = nn.Embedding(10, 128)\n",
    "# 定义transformer，模型维度为128（也就是词向量的维度）\n",
    "transformer = nn.Transformer(d_model=128, batch_first=True) # batch_first一定不要忘记\n",
    "# 将token编码后送给transformer（这里暂时不加Positional Encoding）\n",
    "outputs = transformer(embedding(src), embedding(tgt),\n",
    "                      tgt_mask=tgt_mask,\n",
    "                      src_key_padding_mask=src_key_padding_mask,\n",
    "                      tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "print(outputs.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实战：使用nn.Transformer实现一个简单的Copy任务\n",
    "\n",
    "任务描述：让Transformer预测输入。例如，输入为`[0, 3, 4, 6, 7, 1, 2, 2]`，则期望的输出为`[0, 3, 4, 6, 7, 1]`。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先，我们定义一下句子的最大长度："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "max_length=16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义PositionEncoding类，不需要知道具体什么意思，直接拿过来用即可。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 初始化Shape为(max_len, d_model)的PE (positional encoding)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # 初始化一个tensor [[0, 1, 2, 3, ...]]\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # 这里就是sin和cos括号中的内容，通过e和ln进行了变换\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        # 计算PE(pos, 2i)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 计算PE(pos, 2i+1)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 为了方便计算，在最外面在unsqueeze出一个batch\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # 如果一个参数不参与梯度下降，但又希望保存model的时候将其保存下来\n",
    "        # 这个时候就可以用register_buffer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x 为embedding后的inputs，例如(1,7, 128)，batch size为1,7个单词，单词维度为128\n",
    "        \"\"\"\n",
    "        # 将x和positional encoding相加。\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义我们的Copy模型："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "class CopyTaskModel(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model=128):\n",
    "        super(CopyTaskModel, self).__init__()\n",
    "\n",
    "        # 定义词向量，词典数为10。我们不预测两位小数。\n",
    "        self.embedding = nn.Embedding(num_embeddings=10, embedding_dim=128)\n",
    "        # 定义Transformer。超参是我拍脑袋想的\n",
    "        self.transformer = nn.Transformer(d_model=128, num_encoder_layers=2, num_decoder_layers=2, dim_feedforward=512, batch_first=True)\n",
    "\n",
    "        # 定义位置编码器\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=0)\n",
    "\n",
    "        # 定义最后的线性层，这里并没有用Softmax，因为没必要。\n",
    "        # 因为后面的CrossEntropyLoss中自带了\n",
    "        self.predictor = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 生成mask\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size()[-1])\n",
    "        src_key_padding_mask = CopyTaskModel.get_key_padding_mask(src)\n",
    "        tgt_key_padding_mask = CopyTaskModel.get_key_padding_mask(tgt)\n",
    "\n",
    "        # 对src和tgt进行编码\n",
    "        src = self.embedding(src)\n",
    "        tgt = self.embedding(tgt)\n",
    "        # 给src和tgt的token增加位置信息\n",
    "        src = self.positional_encoding(src)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        # 将准备好的数据送给transformer\n",
    "        out = self.transformer(src, tgt,\n",
    "                               tgt_mask=tgt_mask,\n",
    "                               src_key_padding_mask=src_key_padding_mask,\n",
    "                               tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "        \"\"\"\n",
    "        这里直接返回transformer的结果。因为训练和推理时的行为不一样，\n",
    "        所以在该模型外再进行线性层的预测。\n",
    "        \"\"\"\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_padding_mask(tokens):\n",
    "        \"\"\"\n",
    "        用于key_padding_mask\n",
    "        \"\"\"\n",
    "        key_padding_mask = torch.zeros(tokens.size())\n",
    "        key_padding_mask[tokens == 2] = -torch.inf\n",
    "        return key_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "model = CopyTaskModel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里简单的尝试下我们定义的模型："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 128])\n",
      "tensor([[[ 2.1870e-01,  1.3451e-01,  7.4523e-01, -1.1865e+00, -9.1054e-01,\n",
      "           6.0285e-01,  8.3666e-02,  5.3425e-01,  2.2247e-01, -3.6559e-01,\n",
      "          -5.5751e-01, -1.0966e+00,  8.2621e-01, -1.3470e-01, -2.4268e+00,\n",
      "           1.2707e+00,  3.6751e-01,  1.1104e+00, -2.2421e+00,  2.7835e-01,\n",
      "           1.2738e-01, -4.6274e-01, -1.3117e+00,  1.0418e+00, -5.4291e-01,\n",
      "          -5.7086e-01,  1.6255e+00,  5.9694e-01, -8.9681e-02,  2.5760e+00,\n",
      "          -6.3263e-02,  1.5615e+00,  5.7556e-01, -1.9405e-01, -1.8626e-01,\n",
      "           1.8615e+00, -8.5876e-01,  2.0918e+00,  2.0781e+00,  9.7784e-02,\n",
      "          -1.4695e+00, -7.5358e-01,  2.4817e-01,  9.0796e-01, -6.4562e-01,\n",
      "          -5.9509e-01, -1.4831e-01, -4.2904e-01, -1.6250e+00, -1.1137e-01,\n",
      "           5.1188e-01,  1.5920e+00, -5.9974e-01, -9.2101e-01,  1.1122e+00,\n",
      "          -1.9916e-01, -8.1688e-01,  1.7918e+00, -8.9460e-01, -1.0480e+00,\n",
      "           9.4339e-01, -1.3625e+00,  1.0236e+00, -1.7010e+00, -7.7945e-01,\n",
      "           2.1215e-01, -3.7718e-01,  1.1313e+00, -2.7844e-01,  6.4378e-01,\n",
      "           2.9156e-01,  7.5492e-03, -3.2942e-01, -5.3091e-01, -2.7385e-01,\n",
      "          -4.1747e-01, -5.7335e-01, -3.5215e-01, -1.0593e+00, -4.1506e-01,\n",
      "           6.9059e-01, -1.0220e+00, -1.9010e+00,  6.7636e-01, -3.8494e-01,\n",
      "           1.8274e+00, -4.0000e-01,  2.5775e+00, -1.0572e+00, -7.0499e-01,\n",
      "          -7.2972e-01, -6.6457e-01, -6.6089e-01, -4.4751e-03, -7.6865e-01,\n",
      "           1.3528e+00, -5.1770e-01, -8.3581e-01,  2.9472e-01,  3.0269e-01,\n",
      "           2.2924e-01,  2.3092e+00,  5.0386e-01,  7.6655e-01, -4.5006e-01,\n",
      "           2.0061e+00,  2.8232e-01, -3.3425e-01, -9.1471e-01,  1.5199e-01,\n",
      "           7.8288e-01, -1.3794e-01, -1.2385e+00,  1.3233e+00,  3.9157e-01,\n",
      "           3.4920e-01, -2.8034e-01, -2.4535e+00,  8.8104e-01, -4.2614e-01,\n",
      "          -9.0450e-01,  1.1899e+00, -4.4632e-01, -9.3057e-01,  5.1601e-01,\n",
      "           2.2789e-01, -3.4483e-01, -2.5807e-01],\n",
      "         [ 6.1016e-02,  4.2054e-01,  9.2361e-01, -3.1808e-04,  5.7947e-01,\n",
      "          -8.9896e-01, -9.8781e-01,  1.5742e-01, -7.2288e-01, -5.5188e-01,\n",
      "          -7.6050e-01,  3.3788e-01,  6.2674e-01, -1.0841e+00, -1.8315e+00,\n",
      "           1.2929e+00,  1.0875e+00, -3.0721e-01, -1.3344e+00,  7.8113e-01,\n",
      "           5.4649e-01, -2.8647e-01, -5.0344e-01,  2.8388e-01, -7.4472e-01,\n",
      "          -5.6132e-01,  1.1820e+00, -1.5411e-04,  7.6284e-01,  2.2090e+00,\n",
      "           2.7744e-01,  8.9090e-01,  1.0675e+00, -4.0114e-01,  3.4855e-01,\n",
      "           2.1241e+00, -1.3490e-01,  1.0939e+00,  1.1489e+00,  1.6092e+00,\n",
      "           8.3099e-01, -1.5126e+00,  1.4081e+00,  1.8769e+00,  2.7105e-02,\n",
      "          -3.3790e-02,  1.2586e+00, -2.1884e+00, -1.5911e+00, -1.0103e+00,\n",
      "          -2.7878e-01,  5.1189e-02, -4.0404e-01, -1.9384e+00,  1.8664e+00,\n",
      "          -3.7104e-01, -3.5436e-01,  2.6129e+00, -6.4077e-01, -9.1455e-01,\n",
      "           3.9641e-01, -1.3665e+00, -2.8636e-01, -9.2739e-01, -7.6327e-01,\n",
      "           3.4681e-01, -4.9940e-01,  2.9067e-02, -1.0245e+00,  1.1655e+00,\n",
      "          -2.4094e-01,  1.7653e-01, -8.8863e-01,  3.8980e-01,  1.8305e-01,\n",
      "          -2.2506e-01,  1.8104e-01,  7.9180e-02,  2.5351e-01, -5.5694e-01,\n",
      "           1.1941e+00, -9.2051e-01, -1.8481e+00,  1.3876e+00, -3.9041e-02,\n",
      "           2.3089e+00, -2.8268e-01,  1.4444e+00, -1.2374e+00, -2.5927e-01,\n",
      "           1.1807e-02, -6.2722e-01, -5.7803e-01, -3.2695e-01, -1.9837e+00,\n",
      "           1.0801e+00, -1.2215e+00, -1.2193e+00,  7.7026e-01, -6.2241e-01,\n",
      "           1.5452e+00,  2.6427e+00, -1.0129e-01, -2.8827e-01, -1.8562e-01,\n",
      "           7.4358e-01,  9.9515e-01,  1.5680e+00,  7.0597e-01,  2.6742e-02,\n",
      "          -3.5706e-01, -1.0795e+00, -1.6367e+00,  2.4001e-02,  6.2685e-02,\n",
      "          -9.2826e-01, -2.1456e-01, -7.8796e-01,  8.8380e-01, -1.0842e+00,\n",
      "          -9.7920e-01, -5.6016e-01, -5.5987e-01, -1.3029e-01,  9.8843e-02,\n",
      "          -7.3102e-01,  7.6287e-02, -5.9726e-01],\n",
      "         [ 1.4557e+00, -3.9292e-01,  1.0590e+00, -2.1077e+00,  3.8949e-01,\n",
      "          -8.0650e-01, -1.0360e+00,  1.5118e+00, -1.2749e+00, -2.7561e-01,\n",
      "          -7.8853e-01,  3.1756e-01, -3.1924e-01,  3.3473e-01, -1.1650e+00,\n",
      "           2.2572e-01,  1.0879e+00, -1.6320e-01, -6.2736e-01, -2.8034e-01,\n",
      "           3.4558e-01, -9.7842e-01, -1.6191e+00,  3.2032e-01, -7.9744e-01,\n",
      "          -1.2195e+00,  2.6720e-01,  4.1308e-01,  1.5703e-02,  2.7779e+00,\n",
      "          -2.8443e-01,  7.2790e-01,  8.2411e-01, -6.6469e-01, -1.3236e-01,\n",
      "           2.2133e+00, -2.2755e-01,  1.5614e+00, -1.0771e+00,  1.2571e+00,\n",
      "           1.0722e+00, -2.4606e+00,  1.2342e-01,  5.0227e-01, -2.3854e-01,\n",
      "           6.7147e-01, -2.5649e-01,  1.2790e+00, -2.4953e-01,  1.9232e-01,\n",
      "          -1.9844e+00, -5.7017e-02,  7.6219e-01, -8.4591e-02,  1.0237e+00,\n",
      "           4.9506e-01, -7.1470e-01,  2.1940e+00,  2.3526e-01,  2.8545e-01,\n",
      "          -1.0589e+00, -9.5218e-01, -2.8132e-01, -1.2225e+00, -3.7050e-01,\n",
      "           1.3117e+00, -6.9110e-01,  1.2493e+00, -1.7354e+00,  7.6498e-01,\n",
      "           5.4057e-01,  1.2246e+00, -2.3818e+00, -1.6766e+00, -2.3022e-01,\n",
      "           3.5299e-01, -1.6548e+00, -4.2231e-01,  1.0384e-01, -1.2787e-01,\n",
      "           1.9478e-02,  9.2910e-01, -5.3013e-01,  1.3733e+00, -8.7952e-01,\n",
      "           8.7257e-01, -1.7140e-01,  8.5230e-01, -1.6862e+00, -2.9999e-01,\n",
      "           1.0520e+00,  6.2533e-01, -8.9171e-01, -2.1912e-01, -2.0046e+00,\n",
      "          -1.4586e-01, -8.6180e-01, -6.0074e-01,  2.2633e-02, -7.6782e-01,\n",
      "           8.8688e-01,  2.2277e+00, -4.7052e-01,  4.0908e-01, -1.6069e-01,\n",
      "           1.8021e+00,  3.5166e-01,  1.9566e+00,  5.7533e-01, -6.7452e-02,\n",
      "           1.4743e-01, -6.4661e-01, -1.3588e+00, -6.1649e-01,  4.5831e-01,\n",
      "           3.9856e-01, -6.3630e-01,  3.5454e-02,  6.6012e-01, -1.1424e-01,\n",
      "          -3.9443e-01,  1.6000e+00, -3.6741e-01, -2.5661e-01,  1.2535e+00,\n",
      "          -7.3937e-01, -4.7356e-02,  2.5128e-02],\n",
      "         [ 1.0875e+00, -5.3552e-01,  1.3804e+00, -1.9563e+00, -4.9303e-01,\n",
      "          -1.9830e+00, -2.5611e-02,  5.5901e-01, -5.7023e-03, -6.1867e-01,\n",
      "          -2.6225e-01, -4.9553e-01,  2.5164e-01, -2.0500e-01, -9.6523e-01,\n",
      "          -1.0165e+00,  1.2950e+00, -1.7823e-01, -1.1381e+00,  7.4374e-01,\n",
      "           4.0771e-01, -8.7311e-01, -2.6830e-01,  2.1984e-01, -7.3292e-01,\n",
      "          -1.6769e+00,  1.2840e+00,  1.2964e+00,  1.9137e-01,  3.3830e+00,\n",
      "          -2.9771e-01,  1.6377e+00,  5.8370e-01, -9.8760e-01, -6.2222e-01,\n",
      "           2.2647e+00,  5.2946e-01,  1.3528e+00,  1.4178e+00,  1.0101e+00,\n",
      "          -3.7104e-01, -1.1811e+00,  6.7599e-01,  1.9661e+00, -6.1040e-01,\n",
      "           5.1653e-01, -9.1468e-01, -2.6076e-01, -1.6064e+00, -1.2964e+00,\n",
      "          -1.0377e+00, -1.0083e+00,  5.3279e-01, -8.4671e-01,  6.5964e-01,\n",
      "           6.9045e-02, -3.4449e-01,  9.7198e-01, -7.9049e-01, -3.7346e-01,\n",
      "           5.5596e-01, -1.0416e-01,  4.8236e-01, -9.4754e-01,  7.3020e-01,\n",
      "           1.3368e+00, -5.4300e-01,  3.3582e-01, -1.0529e+00,  9.1038e-01,\n",
      "          -5.5169e-01,  4.2371e-01, -1.0091e+00,  4.2137e-01, -7.0720e-02,\n",
      "           3.8396e-02, -9.7869e-02, -2.8247e-01, -1.6401e-01, -3.8118e-01,\n",
      "          -1.7695e-01,  5.6945e-02, -1.2478e+00,  1.4759e+00, -1.1058e+00,\n",
      "           6.6099e-01,  7.7179e-01,  9.0377e-01, -1.3706e+00, -3.7753e-02,\n",
      "           2.4726e-03,  1.5407e-01, -5.2534e-01,  4.5049e-01, -1.4317e+00,\n",
      "           1.9160e+00, -8.3724e-01, -2.3812e+00,  4.5827e-01, -1.5458e+00,\n",
      "           1.1669e+00,  1.7572e+00,  6.5896e-01, -1.8883e-01,  3.4709e-01,\n",
      "           2.1170e+00,  6.9119e-01,  4.7237e-01, -1.3897e-01, -1.9184e+00,\n",
      "          -7.6533e-01, -2.6423e-01, -2.9801e-01,  5.9588e-01,  2.1053e+00,\n",
      "           3.4093e-01, -1.0768e+00, -1.4769e+00,  2.2226e-01,  3.1296e-01,\n",
      "           1.7114e-01,  4.1777e-01, -1.4248e+00,  1.5697e-01, -5.9601e-01,\n",
      "           8.9818e-01, -7.4755e-02, -7.3844e-01],\n",
      "         [-2.3362e-01, -1.7176e+00,  1.1255e+00, -1.5461e+00, -1.2555e+00,\n",
      "          -1.6738e+00, -9.3274e-01,  7.0116e-01, -6.4265e-01, -9.8397e-01,\n",
      "          -1.2352e+00, -4.0722e-01,  5.0449e-02, -9.3308e-01, -1.4518e+00,\n",
      "          -1.1042e+00,  6.8015e-01, -4.2381e-01,  1.2844e-01,  3.8452e-01,\n",
      "           1.0616e-02, -3.0201e-01, -3.7847e-01,  1.1584e+00, -8.4693e-02,\n",
      "          -6.3850e-01,  2.0260e-01,  4.0496e-01,  7.9334e-01,  2.5753e+00,\n",
      "           5.0174e-01,  2.2089e-01,  6.5587e-01, -7.3735e-02,  2.4315e-01,\n",
      "           2.1284e+00, -3.1031e-01,  1.4562e+00, -2.3796e-01,  2.6159e+00,\n",
      "          -6.3548e-02, -1.4540e+00,  8.2298e-02,  1.2518e+00, -1.0321e+00,\n",
      "          -1.6314e+00, -1.2466e+00, -9.6328e-01, -1.0249e+00,  3.1758e-01,\n",
      "          -5.4944e-01,  6.8099e-01, -3.3788e-01, -1.9811e+00,  2.5397e+00,\n",
      "           4.3345e-01,  3.1534e-01,  1.4372e+00,  1.5117e-01, -7.5165e-01,\n",
      "           1.1532e-01, -1.5197e+00,  3.0067e-01, -5.6678e-01, -8.3566e-01,\n",
      "           9.5614e-01,  6.2965e-02,  9.3865e-01, -2.2734e+00, -3.8921e-02,\n",
      "          -7.4269e-01,  8.4958e-01, -1.1603e-01, -4.4107e-01, -2.4610e-01,\n",
      "           5.7020e-01, -7.4818e-01, -3.1419e-01,  5.1454e-01, -3.8133e-01,\n",
      "          -1.0507e+00, -5.9302e-02, -7.5152e-01,  1.7463e+00, -1.0056e+00,\n",
      "           1.0789e+00,  2.5723e-01,  7.5790e-01, -8.1673e-01, -3.1548e-02,\n",
      "           2.5901e-01,  3.3113e-01, -6.1365e-01, -2.2551e-02, -1.7586e+00,\n",
      "           1.5731e+00, -6.0029e-01, -1.3659e-01,  7.6794e-01, -1.1025e+00,\n",
      "           3.8865e-01,  2.6963e+00,  1.0807e+00, -5.0879e-02,  9.9070e-01,\n",
      "           1.5183e+00,  4.7676e-01,  2.5010e+00,  5.4112e-01,  6.0843e-01,\n",
      "          -9.4463e-01, -3.9516e-01, -8.3626e-01, -3.5792e-01,  1.4078e+00,\n",
      "           1.5628e-01, -1.6484e-01, -6.1058e-01,  1.4334e+00, -8.2226e-01,\n",
      "          -8.9414e-02, -4.1290e-02, -1.8803e-01,  1.3839e+00, -9.9996e-03,\n",
      "          -5.4014e-01, -3.3067e-01, -3.5163e-01],\n",
      "         [-5.7500e-01,  1.0904e+00,  5.9359e-01, -3.0759e+00, -1.4243e+00,\n",
      "          -1.4658e+00, -7.4382e-01,  2.8641e-02,  1.6405e+00, -9.7434e-01,\n",
      "          -1.1418e+00, -3.8018e-01,  5.0001e-01, -2.2578e-01,  3.3084e-02,\n",
      "          -2.5963e-01,  1.2726e-01, -5.2250e-01, -4.5246e-01, -1.2774e+00,\n",
      "           6.0559e-01, -2.1884e-01, -5.0790e-01,  2.1571e+00,  5.7490e-01,\n",
      "          -5.3950e-01,  7.8421e-01,  3.8215e-01,  6.5490e-01,  1.9515e+00,\n",
      "           5.1503e-01,  1.2626e+00,  6.6930e-01, -8.2599e-02, -5.7480e-01,\n",
      "           3.0842e+00,  3.9637e-01,  1.2338e+00,  9.9712e-01,  1.7383e+00,\n",
      "           2.0260e-01, -1.3155e+00,  2.3277e-01,  1.6225e+00,  8.6025e-02,\n",
      "          -8.0791e-01, -8.4525e-01, -2.4816e-01, -1.0268e+00, -1.1576e+00,\n",
      "          -9.3753e-01,  7.1413e-01,  3.2358e-01, -1.0823e+00,  2.7559e+00,\n",
      "          -1.4093e-01, -1.8877e-01,  5.0347e-01, -7.4305e-01, -8.9821e-01,\n",
      "           5.4390e-01, -1.1280e+00, -1.8778e-01, -1.0581e+00,  1.4271e-01,\n",
      "           6.4173e-01, -1.1908e+00,  1.1671e+00, -1.2952e+00,  5.7873e-01,\n",
      "          -9.8690e-01,  8.4781e-01, -1.1269e+00, -3.5327e-01, -4.3229e-01,\n",
      "          -9.0301e-02,  1.8953e-01, -4.6887e-01,  4.2695e-01, -2.8312e-01,\n",
      "          -4.5843e-01, -6.7449e-01, -2.7392e+00,  1.7734e+00, -2.6405e-01,\n",
      "           1.4497e+00,  4.5450e-01,  1.2574e+00, -4.0350e-01, -8.3857e-01,\n",
      "          -5.1735e-01,  3.2962e-01, -1.3629e+00, -9.1425e-02, -1.8298e+00,\n",
      "           7.2969e-01, -6.6256e-01, -1.1089e+00,  1.1796e+00, -9.0771e-01,\n",
      "           6.6103e-02,  1.3940e+00,  3.1740e-01, -4.8933e-01,  6.8387e-01,\n",
      "           2.1287e+00,  1.9047e-01,  1.6740e+00, -8.1837e-01,  8.4285e-01,\n",
      "          -5.9555e-01, -1.7753e-01, -9.8528e-03,  3.3854e-01,  6.3327e-01,\n",
      "           3.4098e-01,  4.2408e-01, -1.2777e+00,  8.3022e-01, -2.1187e-01,\n",
      "          -1.1534e+00, -4.2180e-01, -9.6979e-02,  4.7901e-01,  4.0590e-01,\n",
      "          -4.8624e-01, -2.7504e-01,  3.8539e-01],\n",
      "         [-2.0495e-01, -3.0547e-01,  6.0393e-01, -2.8983e+00, -5.4151e-01,\n",
      "          -6.1446e-01, -1.4244e+00,  1.4708e+00,  1.2072e+00, -6.1190e-01,\n",
      "          -1.3072e+00, -1.2908e+00, -5.7707e-02, -6.8420e-02, -8.9572e-01,\n",
      "          -6.2441e-01,  3.2379e-01, -4.6628e-01, -3.3837e-01, -7.2635e-01,\n",
      "           3.8244e-01, -1.2187e+00, -7.3214e-01,  7.4474e-01,  3.8799e-01,\n",
      "          -3.0535e-01,  1.7974e+00,  1.7626e-01,  2.4973e-01,  2.5515e+00,\n",
      "           4.4802e-01,  1.3810e+00,  9.6059e-01, -5.3388e-01, -7.1215e-01,\n",
      "           2.9062e+00,  1.2148e-01,  1.7999e+00,  1.2678e+00,  1.5671e+00,\n",
      "           1.3459e-01, -1.4930e+00,  8.6701e-02,  1.6098e+00, -3.0932e-01,\n",
      "          -6.3416e-01, -9.4528e-01,  6.7238e-02, -7.7711e-01, -8.6794e-01,\n",
      "          -8.8443e-01,  4.0429e-01,  2.4025e-01, -1.6811e+00,  2.8723e+00,\n",
      "           6.1038e-01,  5.6099e-01,  1.0339e+00, -1.2211e+00, -3.2919e-01,\n",
      "           5.1814e-01, -1.2599e+00,  4.9584e-01, -8.1371e-01,  9.8001e-02,\n",
      "           9.5160e-01, -7.6856e-01,  1.3713e+00, -1.5124e+00,  9.6000e-01,\n",
      "          -9.4459e-01,  3.8470e-01, -5.3851e-01, -3.6376e-01, -9.5164e-01,\n",
      "           4.7041e-01,  2.2549e-01, -6.8064e-02,  7.7033e-01, -9.2431e-01,\n",
      "           2.2875e-01, -6.2558e-01, -2.8724e+00,  1.6043e+00, -8.4780e-01,\n",
      "           9.6164e-01,  2.3446e-02,  2.0031e+00, -7.4849e-01, -1.3216e+00,\n",
      "          -3.6645e-01,  2.1453e-01, -1.0831e+00, -1.4257e-01, -1.3703e+00,\n",
      "          -7.1361e-02,  4.1723e-02, -6.6489e-01,  1.3572e+00, -5.8208e-01,\n",
      "           4.8458e-01,  1.3420e+00,  4.6586e-01,  5.9697e-02,  1.5310e-01,\n",
      "           1.6750e+00,  5.0480e-01,  1.1786e+00, -7.6603e-01, -1.8664e-01,\n",
      "          -6.0069e-01, -2.7068e-01, -2.7476e-01, -3.7432e-01,  7.7260e-01,\n",
      "           3.4725e-01,  2.0215e-01, -1.4885e-01,  3.8420e-01, -1.4045e+00,\n",
      "          -9.1266e-01,  1.7342e-01, -5.7250e-02,  7.1583e-02,  7.0782e-01,\n",
      "          -3.5137e-01,  5.1000e-01, -4.7047e-01]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src = torch.LongTensor([[0, 3, 4, 5, 6, 1, 2, 2]])\n",
    "tgt = torch.LongTensor([[3, 4, 5, 6, 1, 2, 2]])\n",
    "out = model(src, tgt)\n",
    "print(out.size())\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "没什么问题，那就接着定义损失函数和优化器，因为是多分类问题，所以用CrossEntropyLoss:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "接着再定义一个生成随时数据的工具函数："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "def generate_random_batch(batch_size, max_length=16):\n",
    "    src = []\n",
    "    for i in range(batch_size):\n",
    "        # 随机生成句子长度\n",
    "        random_len = random.randint(1, max_length - 2)\n",
    "        # 随机生成句子词汇，并在开头和结尾增加<bos>和<eos>\n",
    "        random_nums = [0] + [random.randint(3, 9) for _ in range(random_len)] + [1]\n",
    "        # 如果句子长度不足max_length，进行填充\n",
    "        random_nums = random_nums + [2] * (max_length - random_len - 2)\n",
    "        src.append(random_nums)\n",
    "    src = torch.LongTensor(src)\n",
    "    # tgt不要最后一个token\n",
    "    tgt = src[:, :-1]\n",
    "    # tgt_y不要第一个的token\n",
    "    tgt_y = src[:, 1:]\n",
    "    # 计算tgt_y，即要预测的有效token的数量\n",
    "    n_tokens = (tgt_y != 2).sum()\n",
    "\n",
    "    # 这里的n_tokens指的是我们要预测的tgt_y中有多少有效的token，后面计算loss要用\n",
    "    return src, tgt, tgt_y, n_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0, 7, 6, 8, 7, 1],\n         [0, 9, 4, 1, 2, 2]]),\n tensor([[0, 7, 6, 8, 7],\n         [0, 9, 4, 1, 2]]),\n tensor([[7, 6, 8, 7, 1],\n         [9, 4, 1, 2, 2]]),\n tensor(8))"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_batch(batch_size=2, max_length=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " 开始进行训练："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40, total_loss: 3.570814609527588\n",
      "Step 80, total_loss: 2.4842987060546875\n",
      "Step 120, total_loss: 2.2327382564544678\n",
      "Step 160, total_loss: 2.1484735012054443\n",
      "Step 200, total_loss: 2.1435012817382812\n",
      "Step 240, total_loss: 1.960964560508728\n",
      "Step 280, total_loss: 1.885743260383606\n",
      "Step 320, total_loss: 1.817548394203186\n",
      "Step 360, total_loss: 1.6362932920455933\n",
      "Step 400, total_loss: 1.608886480331421\n",
      "Step 440, total_loss: 1.3981385231018066\n",
      "Step 480, total_loss: 1.3702815771102905\n",
      "Step 520, total_loss: 1.3767616748809814\n",
      "Step 560, total_loss: 1.4036777019500732\n",
      "Step 600, total_loss: 1.3541620969772339\n",
      "Step 640, total_loss: 1.0286974906921387\n",
      "Step 680, total_loss: 1.2028312683105469\n",
      "Step 720, total_loss: 1.195434331893921\n",
      "Step 760, total_loss: 0.9649490118026733\n",
      "Step 800, total_loss: 0.9759257435798645\n",
      "Step 840, total_loss: 0.8790917992591858\n",
      "Step 880, total_loss: 0.7445364594459534\n",
      "Step 920, total_loss: 0.8278495073318481\n",
      "Step 960, total_loss: 0.7880322337150574\n",
      "Step 1000, total_loss: 0.713218092918396\n",
      "Step 1040, total_loss: 0.7416156530380249\n",
      "Step 1080, total_loss: 0.6479987502098083\n",
      "Step 1120, total_loss: 0.5799983143806458\n",
      "Step 1160, total_loss: 0.5513543486595154\n",
      "Step 1200, total_loss: 0.531852126121521\n",
      "Step 1240, total_loss: 0.5569692254066467\n",
      "Step 1280, total_loss: 0.6862483024597168\n",
      "Step 1320, total_loss: 0.5694398880004883\n",
      "Step 1360, total_loss: 0.5214311480522156\n",
      "Step 1400, total_loss: 0.47019636631011963\n",
      "Step 1440, total_loss: 0.3765433430671692\n",
      "Step 1480, total_loss: 0.5350366830825806\n",
      "Step 1520, total_loss: 0.45316848158836365\n",
      "Step 1560, total_loss: 0.36305320262908936\n",
      "Step 1600, total_loss: 0.5585678219795227\n",
      "Step 1640, total_loss: 0.6126410365104675\n",
      "Step 1680, total_loss: 0.48860710859298706\n",
      "Step 1720, total_loss: 0.31879958510398865\n",
      "Step 1760, total_loss: 0.30813539028167725\n",
      "Step 1800, total_loss: 0.3209533095359802\n",
      "Step 1840, total_loss: 0.3597569465637207\n",
      "Step 1880, total_loss: 0.2530040442943573\n",
      "Step 1920, total_loss: 0.4518987536430359\n",
      "Step 1960, total_loss: 0.37290623784065247\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "for step in range(2000):\n",
    "    # 生成数据\n",
    "    src, tgt, tgt_y, n_tokens = generate_random_batch(batch_size=2, max_length=max_length)\n",
    "\n",
    "    # 清空梯度\n",
    "    optimizer.zero_grad()\n",
    "    # 进行transformer的计算\n",
    "    out = model(src, tgt)\n",
    "    # 将结果送给最后的线性层进行预测\n",
    "    out = model.predictor(out)\n",
    "    \"\"\"\n",
    "    计算损失。由于训练时我们的是对所有的输出都进行预测，所以需要对out进行reshape一下。\n",
    "            我们的out的Shape为(batch_size, 词数, 词典大小)，view之后变为：\n",
    "            (batch_size*词数, 词典大小)。\n",
    "            而在这些预测结果中，我们只需要对非<pad>部分进行，所以需要进行正则化。也就是\n",
    "            除以n_tokens。\n",
    "    \"\"\"\n",
    "    loss = criteria(out.contiguous().view(-1, out.size(-1)), tgt_y.contiguous().view(-1)) / n_tokens\n",
    "    # 计算梯度\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss\n",
    "\n",
    "    # 每40次打印一下loss\n",
    "    if step != 0 and step % 40 == 0:\n",
    "        print(\"Step {}, total_loss: {}\".format(step, total_loss))\n",
    "        total_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在完成模型训练后，我们来使用一下我们的模型："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "# 随便定义一个src\n",
    "src = torch.LongTensor([[0, 4, 3, 4, 6, 8, 9, 9, 8, 1, 2, 2]])\n",
    "# tgt从<bos>开始，看看能不能重新输出src中的值\n",
    "tgt = torch.LongTensor([[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 4, 3, 4, 6, 8, 9, 9, 8, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 一个一个词预测，直到预测为<eos>，或者达到句子最大长度\n",
    "for i in range(max_length):\n",
    "    # 进行transformer计算\n",
    "    out = model(src, tgt)\n",
    "    # 预测结果，因为只需要看最后一个词，所以取`out[:, -1]`\n",
    "    predict = model.predictor(out[:, -1])\n",
    "    # 找出最大值的index\n",
    "    y = torch.argmax(predict, dim=1)\n",
    "    # 和之前的预测结果拼接到一起\n",
    "    tgt = torch.concat([tgt, y.unsqueeze(0)], dim=1)\n",
    "\n",
    "    # 如果为<eos>，说明预测结束，跳出循环\n",
    "    if y == 1:\n",
    "        break\n",
    "print(tgt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，我们的模型成功预测了src的输入。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "# 参考资料：\n",
    "\n",
    "[nn.Transformer官方文档](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html): https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "[层层剖析，让你彻底搞懂Self-Attention、MultiHead-Attention和Masked-Attention的机制和原理](https://blog.csdn.net/zhaohongfei_358/article/details/122861751): https://blog.csdn.net/zhaohongfei_358/article/details/122861751"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
